{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.12"
    },
    "colab": {
      "name": "MMAI5000_assignment3 official.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yFvzvX_LIOwa",
        "GmPP7LoDIOwk"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiRJVrYrIOvR"
      },
      "source": [
        "# AI Fundamentals - Assignment 3\n",
        "\n",
        "This assignment requires you to use [Tensorflow](https://www.tensorflow.org) and [Keras](https://keras.io/). Keras is a high-level Deep Learning API written in Python working as an interface to TensorFlow.\n",
        "\n",
        "This assignment is divided in two parts. In the first part you will learn about Keras with the help of the example below and the Keras [documentation](https://keras.io/). In the second part, you will practise training a Deep Learning model.\n",
        "\n",
        "## How to submit\n",
        "Submit by uploading this notebook to Canvas. It should include **plots**, **results** and **code** showing how the results were genereated.  Remember to name your file(s) appropriately.\n",
        "It is due on 11:59 of December 9, 2020.\n",
        "\n",
        "## Installation\n",
        "Instructions can be found here:\n",
        "* [Tensorflow](https://www.tensorflow.org/install/)\n",
        "\n",
        "Since Tensorflow 2.0, Keras is included in Tensorflow and will be automatically installed with Tensorflow. It can be accessed as ```tensorflow.keras```\n",
        "\n",
        "I recommend using ```pip```. For Tensorflow is it sufficient to install the CPU version. The GPU version requires a good workstation with high-end Nvidia GPU(s), and it is not necessary for this tutorial.\n",
        "\n",
        "If you're using a virtualenv:\n",
        "```\n",
        "pip3 install tensorflow\n",
        "```\n",
        "Add ```sudo``` for a systemwide installation (i.e. no ```virtualenv```).\n",
        "```\n",
        "sudo pip3 install tensorflow\n",
        "```\n",
        "Make sure that you have ```sklearn```, ```matplotlib``` and ```numpy``` installed, too.\n",
        "\n",
        "\n",
        "## Part 1 - understand a model\n",
        "\n",
        "### Optimizers\n",
        "\n",
        "Loss is the penalty for a bad prediction. That is, loss is a number indicating how bad the model's prediction was on a single example. If the model's prediction is perfect, the loss is zero; otherwise, the loss is greater than zero. The goal of training a model is to find a set of weights and biases (i.e. parameters) that have, on average, a low loss across all examples. The term cost is used interchangably with loss. See the [loss section](https://keras.io/losses/) in the Keras documentation for a list and descriptions of what is available.\n",
        "\n",
        "![Side by side loss](https://drive.google.com/uc?id=1DdbQEQLCLCSw4uPsuf0C1nJCfUICT0Ae)\n",
        "<b>Figure 1.</b> Left: high loss and right: low loss.\n",
        "\n",
        "<!-- https://drive.google.com/file/d/1DdbQEQLCLCSw4uPsuf0C1nJCfUICT0Ae/view?usp=sharing\n",
        "<img src=\"./fig/LossSideBySide.png\" width=\"500\">\n",
        "<figcaption>Figure. Left: high loss and right: low loss.</figcaption>\n",
        " -->\n",
        "The optimizer is the algorithm used to minimize the loss/cost. Optimizers in neural networks work by finding the gradient/derivative of the loss with respect to the parameters (i.e. the weights). \"Gradient\" is the correct term since a we are looking at multi-dimensional systems (i.e. many parameters), however, the terms are often used interchangably. For those who didn't take multivariate calculus, just think of the gradient as a derivative. The derivative of the loss with respect to a parameters tells us how much the loss changes when we nudge a weight up or down. So, by knowing how a given parameter affects the loss the optimizer can change it so as to decrease the loss. The various optimizers differ in how they change the weights. \n",
        "\n",
        "#### Mini-overview over popular optimizers\n",
        "\n",
        "* **Stochastic Gradient Descent (SGD)**. This is the most basic and easy to understand optimizer. It updates the weights in the negative direction of the gradient by taking the average gradient of mini-batch of data (e.g. 20-1000 examples) in each step. Vanilla SGD only has one hyper-parameter, the learning rate.\n",
        "* **Momentum**. This optimizer \"gains speed\" when the gradient has pointed in the same direction for several consecutive updates. That is, it has a momentum and want to keep moving in that direction. It gains momentum by accumulating an exponentially decaying moving average of past gradients. The step size depends on how large and aligned the sequence of gradients are. The most important hyper-parameter is alpha and common values are 0.5 and 0.9.\n",
        "* **Nesterov Momentum**. This is a modification of the standard momentum optimizer.\n",
        "* **AdaGrad**. This optimizer Ada-ptively sets the learning rate depending on the steepness/magnitude of the Grad-ients. This is done so that weights with big gradients get a smaller effective learning rate, and weights with small gradients will get a greater effective learning rate. The result is quicker progress in the more gently sloped directions of the weight space and a slowdown in stepp regions.\n",
        "* **RMSProp**. This is modification of AdaGrad, where the accumulated gradient decays, that is, the influence of previous gradients gradually decreases.\n",
        "* **Adam**. The name comes from \"adaptive moments\", and it is a combination of RMSProp and momentum. It has several hyper-parameters.\n",
        "\n",
        "The above list just gives a quick overview of some of the most common. However, old optimizers are constantly improved and new are developed. SGD and momentum are most basic and easiest to understand and implement. They are still in use, but the more advanced optimizers tend to be better for practical use. Which one to use is generally an emperical question depending on both the data and the model.\n",
        "\n",
        "For a more complete overview of optimization algorithms see [this comparison](http://ruder.io/optimizing-gradient-descent/), and to see what is available in Keras, see the [optimizer section](https://keras.io/optimizers/) of the documentation.\n",
        "\n",
        "See the images below for a comparison of optimizers in a 2D space (NAG: Nesterov accelerated gradient, Adadelta: an extension of AdaGrad).\n",
        "\n",
        "![Contours - optimizer comparison](https://drive.google.com/uc?id=1CmrD-UPZ7EIUjRuO_ib7k9CL1FO2bbLk)\n",
        "<b>Figure 2.</b> Comparison of six different optimizers.\n",
        "\n",
        "\n",
        "![Saddle point - optimizer comparison](https://drive.google.com/uc?id=1QVhN9rAvCjXtGyNZkmFivyyCzNsntObh)\n",
        "<b>Figure 3.</b> Comparison of six different optimizers at a saddle point.\n",
        "\n",
        "<!-- <img src=\"./fig/contours_evaluation_optimizers.gif\" width=\"500\">\n",
        "<img src=\"./fig/saddle_point_evaluation_optimizers.gif\" width=\"500\"> -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCosJUUWIOvs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXY0UaJAIOvw"
      },
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "# for the random seed\n",
        "import tensorflow as tf\n",
        "\n",
        "# set the random seeds to get reproducible results\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(2)\n",
        "\n",
        "# Load data from https://www.openml.org/d/554\n",
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRiKaTO5IOvy",
        "outputId": "9b7a91fc-c9e9-4bd7-b419-fae8af7a4959"
      },
      "source": [
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS4jYcxUIOv3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3optFDWjIOv5",
        "outputId": "44313bcc-17ab-4762-ceeb-0710f4589bd9"
      },
      "source": [
        "print(X.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebayWvavIOv6",
        "outputId": "43913b31-3af2-4de7-d83f-423cdb62270d"
      },
      "source": [
        "print(y.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxoCy6nJIOv8"
      },
      "source": [
        "\n",
        "X, y = X[:1000], y[:1000]\n",
        "X = X.reshape(X.shape[0], 28, 28, 1)\n",
        "# Normalize\n",
        "X = X / 255.\n",
        "# number of unique classes\n",
        "num_classes = len(np.unique(y))\n",
        "y = y.astype(int)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
        "\n",
        "num_tot = y.shape[0]\n",
        "num_train = y_train.shape[0]\n",
        "num_test = y_test.shape[0]\n",
        "\n",
        "y_oh = np.zeros((num_tot, num_classes))\n",
        "y_oh[range(num_tot), y] = 1\n",
        "\n",
        "y_oh_train = np.zeros((num_train, num_classes))\n",
        "y_oh_train[range(num_train), y_train] = 1\n",
        "\n",
        "y_oh_test = np.zeros((num_test, num_classes))\n",
        "y_oh_test[range(num_test), y_test] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUYf7Kj-IOv-",
        "outputId": "92d28771-8160-4a22-c555-1c4c3ca514b9"
      },
      "source": [
        "print(X.shape)\n",
        "print(type(X))\n",
        "X.shape[0]\n",
        "y[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 28, 28, 1)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuZTu_l5IOwD",
        "outputId": "c8d244be-fb5b-4f7b-b53d-b45b69a518cb"
      },
      "source": [
        "X.shape[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quCo92XZIOwG",
        "outputId": "a271cc46-6d01-4dcc-90bc-7da3567fd47d"
      },
      "source": [
        "print(type(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arDYwdILIOwH",
        "outputId": "417efdb6-7d03-469d-ee6a-3efc09d867ea"
      },
      "source": [
        "print(type(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqKm1gguIOwJ",
        "outputId": "cac0234a-d133-480c-f7db-bd1b98ed2b36"
      },
      "source": [
        "print(X.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "et63pWOPIOwK",
        "outputId": "d6fe6981-5ba3-45f5-d31c-50b48dbbbbae"
      },
      "source": [
        "print(y.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGN8d6uzIOwM",
        "outputId": "190c941e-9814-43c7-920f-24d67817aeb8"
      },
      "source": [
        "plt.imshow(X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1bfbcce1c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM6LzkU5IOwN",
        "outputId": "6bb3ae1e-c229-4bf0-95df-0a6b736e581b"
      },
      "source": [
        "plt.imshow(X[4])\n",
        "plt.title(y[4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_eXPbIfIOwO",
        "outputId": "0ccf84fb-537f-4902-e039-57aa59d58a77"
      },
      "source": [
        "print(type(X))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "541hw7orIOwQ",
        "outputId": "a6073bcc-73b2-4167-fccd-0f225df6ac89"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoSDfsJ-IOwS",
        "outputId": "84d85f11-193f-4d23-daab-097f364d364d"
      },
      "source": [
        "y[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf8fKhxSIOwT",
        "outputId": "25a4141a-ac4d-45e9-f936-749b888a5215"
      },
      "source": [
        "np.unique(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5NtXHMSIOwV",
        "outputId": "c98eb5c9-01c0-42a0-c3f3-531efa215a99"
      },
      "source": [
        "y_oh.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5STI6UDIOwX",
        "outputId": "ad664668-1688-474e-8054-26df95371159"
      },
      "source": [
        "range(num_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "range(0, 800)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ5vDVSeIOwY",
        "outputId": "d881bdb7-b815-4273-9408-0962e427f0b6"
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMoJqMVAIOwY",
        "outputId": "7e5a8f30-47d4-4782-957f-3facfad2c92d"
      },
      "source": [
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7 3 8 6 9 0 5 6\n",
            " 0 7 6 1 8 7 9 3 9 8 5 9 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 1 7 1 6\n",
            " 3 0 2 1 1 7 9 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1 5 7 1 7 1 1 6 3 0 2 9\n",
            " 3 1 1 0 4 9 2 0 0 2 0 2 7 1 8 6 4 1 6 3 4 5 9 1 3 3 8 5 4 7 7 4 2 8 5 8 6\n",
            " 7 3 4 6 1 9 9 6 0 3 7 2 8 2 9 4 4 6 4 9 7 0 9 2 9 5 1 5 9 1 2 3 2 3 5 9 1\n",
            " 7 6 2 8 2 2 5 0 7 4 9 7 8 3 2 1 1 8 3 6 1 0 3 1 0 0 1 7 2 7 3 0 4 6 5 2 6\n",
            " 4 7 1 8 9 9 3 0 7 1 0 2 0 3 5 4 6 5 8 6 3 7 5 8 0 9 1 0 3 1 2 2 3 3 6 4 7\n",
            " 5 0 6 2 7 9 8 5 9 2 1 1 4 4 5 6 4 1 2 5 3 9 3 9 0 5 9 6 5 7 4 1 3 4 0 4 8\n",
            " 0 4 3 6 8 7 6 0 9 7 5 7 2 1 1 6 8 9 4 1 5 2 2 9 0 3 9 6 7 2 0 3 5 4 3 6 5\n",
            " 8 9 5 4 7 4 2 7 3 4 8 9 1 9 2 8 7 9 1 8 7 4 1 3 1 1 0 2 3 9 4 9 2 1 6 8 4\n",
            " 7 7 4 4 9 2 5 7 2 4 4 2 1 9 7 2 8 7 6 9 2 2 3 8 1 6 5 1 1 0 2 6 4 5 8 3 1\n",
            " 5 1 9 2 7 4 4 4 8 1 5 8 9 5 6 7 9 9 3 7 0 9 0 6 6 2 3 9 0 7 5 4 8 0 9 4 1\n",
            " 2 8 7 1 2 6 1 0 3 0 1 1 8 2 0 3 9 4 0 5 0 6 1 7 7 8 1 9 2 0 5 1 2 2 7 3 5\n",
            " 4 9 7 1 8 3 9 6 0 3 1 1 2 6 3 5 7 6 8 3 9 5 8 5 7 6 1 1 3 1 7 5 5 5 2 5 8\n",
            " 7 0 9 7 7 5 0 9 0 0 8 9 2 4 8 1 6 1 6 5 1 8 3 4 0 5 5 8 3 6 2 3 9 2 1 1 5\n",
            " 2 1 3 2 8 7 3 7 2 4 6 9 7 2 4 2 8 1 1 3 8 4 0 6 5 9 3 0 9 2 4 7 1 2 9 4 2\n",
            " 6 1 8 9 0 6 6 7 9 9 8 0 1 4 4 6 7 1 5 7 0 3 5 8 4 7 1 2 5 9 5 6 7 5 9 8 8\n",
            " 3 6 9 7 0 7 5 7 1 1 0 7 9 2 3 7 3 2 4 1 6 2 7 5 5 7 4 0 2 6 3 6 4 0 4 2 6\n",
            " 0 0 0 0 3 1 6 2 2 3 1 4 1 5 4 6 4 7 2 8 7 9 2 0 5 1 4 2 8 3 2 4 1 5 4 6 0\n",
            " 7 9 8 4 9 8 0 1 1 0 2 2 3 2 4 4 5 8 6 5 7 7 8 8 9 7 4 7 3 2 0 8 6 8 6 1 6\n",
            " 8 9 4 0 9 0 4 1 5 4 7 5 3 7 4 9 8 5 8 6 3 8 6 9 9 1 8 3 5 8 6 5 9 7 2 5 0\n",
            " 8 5 1 1 0 9 1 8 6 7 0 9 3 0 8 8 9 6 7 8 4 7 5 9 2 6 7 4 5 9 2 3 1 6 3 9 2\n",
            " 2 5 6 8 0 7 7 1 9 8 7 0 9 9 4 6 2 8 5 1 4 1 5 5 1 7 3 6 4 3 2 5 6 4 4 0 4\n",
            " 4 6 7 2 4 3 3 8 0 0 3 2 2 9 8 2 3 7 0 1 1 0 2 3 3 8 4 3 5 7 6 4 7 7 8 5 9\n",
            " 7 0 3 1 6 2 4 3 4 4 7 5 9 6 9 0 7 1 4 2 7 3 6 7 5 8 4 5 5 2 7 1 1 5 6 8 5\n",
            " 8 4 0 7 9 9 2 9 7 7 8 7 4 2 6 9 1 7 0 6 4 2 5 7 0 7 1 0 3 7 6 5 0 6 1 5 1\n",
            " 7 8 5 0 3 4 7 7 5 7 8 6 9 3 8 6 1 0 9 7 1 3 0 5 6 4 4 2 4 4 3 1 7 7 6 0 3\n",
            " 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88rJ3Ro9IOwZ",
        "outputId": "afbdd930-f9cc-4024-e990-c427e7d49bd2"
      },
      "source": [
        "print(y[0],y_oh[0])\n",
        "print(y[1],y_oh[1])\n",
        "print(y[2],y_oh[2])\n",
        "#relationship between y and y_oh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5 [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "0 [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "4 [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFvzvX_LIOwa"
      },
      "source": [
        "### Question 1\n",
        "**The data set**\n",
        "\n",
        "Plot a three examples from the data set.\n",
        "* What type of data are in the data set?\n",
        "\n",
        "    <span style=\"color:red\"> <*float 64 in numpy array, handwritten numbers ranging from 0 to 9*> </span>\n",
        "    \n",
        "\n",
        "* What does the line ```X = X.reshape(X.shape[0], 28, 28, 1)``` do?\n",
        "This reshapes the data to ensure the height and width are 28x28 and 1 represents the color channel. Before reshaping the data was (70000,784)\n",
        "\n",
        "Look at how the encoding of the targets (i.e. ```y```) is changed. E.g. the lines\n",
        "```\n",
        "    y_oh = np.zeros((num_tot, num_classes))\n",
        "    y_oh[range(num_tot), y] = 1\n",
        "```\n",
        "Print out a few rows of ```y``` next to ```y_oh```.\n",
        "* What is the relationship between ```y``` and ```y_oh```?\n",
        "\n",
        "    <span style=\"color:red\"> <y is the index of where 1 is in the y_oh row*> </span>\n",
        "    \n",
        "    \n",
        "* What is the type of encoding in ```y_oh``` called and why is it used?\n",
        "\n",
        "    <span style=\"color:red\"> <one hot encoding and it is used to convert categorical data to integer data because ML algorithms cant work directly with categorical data.> </span>\n",
        "    \n",
        "    \n",
        "* Plot three data examples in the same figure and set the correct label as title. \n",
        "    * It should be possible to see what the data represent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1yqlvfIOwd",
        "outputId": "fe74512e-38b0-4599-a7ea-3ce046538d9e"
      },
      "source": [
        "fig=plt.figure()\n",
        "ax=fig.add_subplot(131)\n",
        "ax.imshow(X[0])\n",
        "ax.set_title(y[0])\n",
        "#3 seperate examples\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vf-DUMskIOwf",
        "outputId": "edf2edb9-d5b0-4cc7-8caa-8e19142456f4"
      },
      "source": [
        "fig=plt.figure()\n",
        "ax=fig.add_subplot(132)\n",
        "ax.imshow(X[1])\n",
        "ax.set_title(y[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNIGxvQuIOwg",
        "outputId": "d4089664-8af3-4ac1-f530-b5de3281ef27"
      },
      "source": [
        "fig=plt.figure()\n",
        "ax=fig.add_subplot(133)\n",
        "ax.imshow(X[2])\n",
        "ax.set_title(y[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '4')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFMhovwRIOwh",
        "outputId": "bd0b3169-5448-45e3-a05e-9bd042c43cb2"
      },
      "source": [
        "fig=plt.figure()\n",
        "ax=fig.add_subplot(131)\n",
        "ax.imshow(X[0])\n",
        "ax.set_title(y[0])\n",
        "\n",
        "ax=fig.add_subplot(132)\n",
        "ax.imshow(X[1])\n",
        "ax.set_title(y[1])\n",
        "\n",
        "ax=fig.add_subplot(133)\n",
        "ax.imshow(X[2])\n",
        "ax.set_title(y[2])\n",
        "#plotting on the same axis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, '4')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZzvLXbSIOwi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0rF0-NGIOwj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qttjcdsOIOwj"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmPP7LoDIOwk"
      },
      "source": [
        "### Question 2\n",
        "**The model**\n",
        "\n",
        "Below is some code for bulding and training a model with Keras.\n",
        "* What type of network is implemented below? I.e. a normal MLP, RNN, CNN, Logistic Regression...?\n",
        "\n",
        "    <span style=\"color:red\"> <cnn> </span>\n",
        "    \n",
        "    \n",
        "* What does ```Dropout()``` do?\n",
        "\n",
        "    <span style=\"color:red\"> <randomly sets input units to 0 with a frequency rate at each step during training time to prevent overfitting> </span>\n",
        "\n",
        "\n",
        "* Which type of activation function is used for the hidden layers?\n",
        "\n",
        "    <span style=\"color:red\"> <relu> </span>\n",
        "\n",
        "\n",
        "* Which type of activation function is used for the output layer?\n",
        "\n",
        "    <span style=\"color:red\"> <softmax> </span>\n",
        "\n",
        "\n",
        "* Why are two different activation functions used?\n",
        "\n",
        "    <span style=\"color:red\"> <softmax is used to represent a probability distribution of possible outcomes (probability input belongs to a given class) and captures thr models confidence in a prediction and relu takes a single number as an input and returns the input if the input is positive and 0 if the input is negative. With 2 activation functions, we create increasingly complex filters.> </span>\n",
        "\n",
        "\n",
        "* What optimizer is used in the model below?\n",
        "\n",
        "    <span style=\"color:red\"> <SGD> </span>\n",
        "\n",
        "\n",
        "* How often are the weights updated (i.e. after how many data examples)?\n",
        "\n",
        "    <span style=\"color:red\"> <32> </span>\n",
        "\n",
        "\n",
        "* What loss function is used?\n",
        "\n",
        "    <span style=\"color:red\"> <Categorical Crossentropy> </span>\n",
        "\n",
        "\n",
        "* How many parameters (i.e. weights and biases, NOT hyper-parameters) does the model have?\n",
        "\n",
        "    <span style=\"color:red\"> <108618> </span>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N7ZXswSIOwm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "C7yOTNFRIOwm",
        "outputId": "3fca299c-fea2-46ce-da7b-937741986f0a"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_oh_train, batch_size=32, epochs=60)\n",
        "                                                                       \n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "25/25 [==============================] - 1s 18ms/step - loss: 2.2322\n",
            "Epoch 2/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 1.3094\n",
            "Epoch 3/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.5476\n",
            "Epoch 4/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.3458\n",
            "Epoch 5/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.2481\n",
            "Epoch 6/60\n",
            "25/25 [==============================] - 0s 18ms/step - loss: 0.1618\n",
            "Epoch 7/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.1702\n",
            "Epoch 8/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.1203\n",
            "Epoch 9/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0991\n",
            "Epoch 10/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0544\n",
            "Epoch 11/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.0416\n",
            "Epoch 12/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.0405\n",
            "Epoch 13/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0346\n",
            "Epoch 14/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0197\n",
            "Epoch 15/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0155\n",
            "Epoch 16/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0179\n",
            "Epoch 17/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.0119\n",
            "Epoch 18/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0071\n",
            "Epoch 19/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0077\n",
            "Epoch 20/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0040\n",
            "Epoch 21/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0042\n",
            "Epoch 22/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0032\n",
            "Epoch 23/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0035\n",
            "Epoch 24/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0023\n",
            "Epoch 25/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0022\n",
            "Epoch 26/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0022\n",
            "Epoch 27/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.0021\n",
            "Epoch 28/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0019\n",
            "Epoch 29/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0019\n",
            "Epoch 30/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0015\n",
            "Epoch 31/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.0018\n",
            "Epoch 32/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0015\n",
            "Epoch 33/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.0013\n",
            "Epoch 34/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0013\n",
            "Epoch 35/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.0012\n",
            "Epoch 36/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0011\n",
            "Epoch 37/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0012\n",
            "Epoch 38/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0011\n",
            "Epoch 39/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0012\n",
            "Epoch 40/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.0011\n",
            "Epoch 41/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.0010\n",
            "Epoch 42/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 9.5394e-04\n",
            "Epoch 43/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 8.7574e-04\n",
            "Epoch 44/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7.5682e-04\n",
            "Epoch 45/60\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 7.8369e-04\n",
            "Epoch 46/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 8.6218e-04\n",
            "Epoch 47/60\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 7.4391e-04\n",
            "Epoch 48/60\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.9564e-04\n",
            "Epoch 49/60\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 7.4031e-04\n",
            "Epoch 50/60\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.5886e-04\n",
            "Epoch 51/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 6.1734e-04\n",
            "Epoch 52/60\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 5.8012e-04\n",
            "Epoch 53/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 5.5293e-04\n",
            "Epoch 54/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 5.6152e-04\n",
            "Epoch 55/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 6.9899e-04\n",
            "Epoch 56/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 6.1618e-04\n",
            "Epoch 57/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 5.2982e-04\n",
            "Epoch 58/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 6.1549e-04\n",
            "Epoch 59/60\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 5.8393e-04\n",
            "Epoch 60/60\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 5.5801e-04\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4677\n",
            "Accuracy: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKZKEidZIOwo",
        "outputId": "ca73b66b-7528-4770-d815-32cddc1f98cd"
      },
      "source": [
        "model.count_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFNsJlYqIOwq"
      },
      "source": [
        "w=model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZ6KI0CxIOwr",
        "outputId": "fb500ae4-fbd6-48da-c829-7d3b000f9372"
      },
      "source": [
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[[-1.55236319e-01,  9.89941508e-02, -1.41920179e-01,\n",
              "           -1.24785520e-01,  3.85339439e-01,  5.58272362e-01,\n",
              "            5.79306558e-02, -7.31276274e-02,  4.55860198e-01,\n",
              "            2.14987785e-01,  2.95400441e-01,  2.68941075e-01,\n",
              "            2.37533137e-01,  5.03332876e-02, -4.89647835e-02,\n",
              "            1.64770558e-01]],\n",
              " \n",
              "         [[ 1.71795413e-02, -1.43696576e-01, -1.49278775e-01,\n",
              "           -2.06572771e-01,  5.81375301e-01,  1.99791446e-01,\n",
              "           -1.14922486e-02, -1.25206918e-01,  3.95626426e-01,\n",
              "            2.34450594e-01,  2.85579771e-01,  3.58075500e-01,\n",
              "            1.41423181e-01,  2.13619739e-01, -1.54381007e-01,\n",
              "            2.31677368e-01]],\n",
              " \n",
              "         [[-6.27504438e-02,  1.21049955e-02, -1.77129760e-01,\n",
              "            2.65367508e-01,  5.73157609e-01,  1.83028191e-01,\n",
              "            1.31303385e-01, -1.16381884e-01,  4.10868198e-01,\n",
              "            3.06587458e-01,  4.94386293e-02,  4.86494064e-01,\n",
              "           -1.77179813e-01,  3.53003651e-01,  2.31179893e-01,\n",
              "            6.21926002e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 1.82581484e-01,  2.94586986e-01, -8.72796476e-02,\n",
              "            2.60664076e-02,  6.78909793e-02,  7.57816136e-01,\n",
              "            1.10982738e-01,  1.65456802e-01,  1.92329824e-01,\n",
              "            1.16653800e-01, -8.80437046e-02,  4.12484974e-01,\n",
              "            2.39350483e-01, -1.22094020e-01, -9.61012170e-02,\n",
              "            1.63127959e-01]],\n",
              " \n",
              "         [[-9.33362916e-02,  2.13585138e-01,  9.62906703e-02,\n",
              "           -1.31145686e-01,  6.80559218e-01,  7.97994494e-01,\n",
              "           -1.88473299e-01, -1.60552904e-01, -1.42268181e-01,\n",
              "            2.38091260e-01, -9.06826183e-02,  1.38093114e-01,\n",
              "            2.09878430e-01, -3.52131538e-02,  3.59979980e-02,\n",
              "            1.61306322e-01]],\n",
              " \n",
              "         [[-2.35576779e-04, -1.73979744e-01, -1.61307439e-01,\n",
              "            4.20573324e-01,  8.23720694e-01,  5.35490274e-01,\n",
              "           -1.24894038e-01, -1.86899275e-01, -9.55106169e-02,\n",
              "            1.81057781e-01, -7.34513551e-02,  2.08834574e-01,\n",
              "           -1.01020753e-01, -1.65430978e-01,  3.86737660e-02,\n",
              "            2.33591229e-01]]],\n",
              " \n",
              " \n",
              "        [[[ 8.19316804e-02,  3.76100153e-01,  2.25622714e-01,\n",
              "            2.45342329e-02,  1.12218618e-01,  5.55708647e-01,\n",
              "           -1.39613971e-01,  2.74412900e-01, -1.48157865e-01,\n",
              "           -1.56739014e-04,  1.47006795e-01, -2.94481963e-02,\n",
              "           -4.47168499e-02,  7.56997466e-02,  1.12776369e-01,\n",
              "           -2.16836080e-01]],\n",
              " \n",
              "         [[-5.48226349e-02,  1.79050028e-01,  1.21924229e-01,\n",
              "            1.57372713e-01,  4.22555745e-01,  7.45595038e-01,\n",
              "           -1.54791802e-01, -3.82680856e-02, -2.85163075e-01,\n",
              "           -2.56298482e-01,  2.45507248e-02,  6.86665177e-02,\n",
              "            3.74531269e-01, -2.02234536e-01, -1.32577777e-01,\n",
              "            1.12399034e-01]],\n",
              " \n",
              "         [[-3.02072074e-02, -4.94850837e-02,  2.38534182e-01,\n",
              "            4.46434855e-01,  7.13832080e-01,  4.00289565e-01,\n",
              "           -7.19290674e-02, -7.22791478e-02,  3.81061323e-02,\n",
              "            3.35206129e-02, -1.69865549e-01, -4.33388390e-02,\n",
              "            3.19783211e-01, -1.12711892e-01,  1.44543394e-01,\n",
              "            2.67226696e-01]]]], dtype=float32),\n",
              " array([ 0.03115262,  0.04587548,  0.028386  ,  0.0129131 , -0.05744756,\n",
              "        -0.04463189,  0.01056373,  0.07387725,  0.00408579, -0.01095089,\n",
              "         0.00677572,  0.0016567 , -0.05077423,  0.0178042 ,  0.00390276,\n",
              "         0.00024267], dtype=float32),\n",
              " array([[[[ 3.24456915e-02,  1.15440913e-01,  3.94919747e-03, ...,\n",
              "            1.05857030e-01,  9.88669228e-03, -8.74034017e-02],\n",
              "          [-2.91936696e-02,  2.52389610e-02, -9.54075754e-02, ...,\n",
              "            7.87171870e-02,  5.15477099e-02, -1.18903294e-01],\n",
              "          [-3.12106740e-02,  1.08699821e-01,  1.53772878e-02, ...,\n",
              "           -1.00680813e-01, -7.52125382e-02, -1.09946020e-01],\n",
              "          ...,\n",
              "          [ 8.58173445e-02, -3.89174074e-02,  4.34264280e-02, ...,\n",
              "           -1.09252505e-01, -9.01485533e-02, -5.82987294e-02],\n",
              "          [-1.07582845e-01,  1.07103787e-01, -2.87194867e-02, ...,\n",
              "           -5.29674217e-02,  8.68739337e-02,  3.93064842e-02],\n",
              "          [-1.00999765e-01,  6.83863014e-02, -7.74186328e-02, ...,\n",
              "            3.72354500e-02, -1.10973671e-01,  1.84278321e-02]],\n",
              " \n",
              "         [[ 6.79043233e-02,  4.35294956e-03,  7.52538294e-02, ...,\n",
              "            5.69127910e-02,  3.20680067e-02, -9.09599885e-02],\n",
              "          [-4.00917418e-02,  1.95349753e-02,  7.31131956e-02, ...,\n",
              "            4.79116291e-02, -5.27225398e-02, -1.50310434e-02],\n",
              "          [-9.89836678e-02, -1.31446242e-01, -1.02024347e-01, ...,\n",
              "            2.14997381e-02,  5.75917214e-02,  7.20683858e-02],\n",
              "          ...,\n",
              "          [-1.06729560e-01, -1.99279841e-03, -1.12369426e-01, ...,\n",
              "            2.43801549e-02,  1.21333795e-02,  2.68344898e-02],\n",
              "          [ 4.70209792e-02,  2.45117061e-02, -5.19450456e-02, ...,\n",
              "           -5.99320605e-02,  5.62254747e-04,  1.16945580e-01],\n",
              "          [-6.47424487e-04,  1.12925954e-02,  1.12046294e-01, ...,\n",
              "            8.93665329e-02,  1.23202957e-01,  7.28627294e-02]],\n",
              " \n",
              "         [[ 3.59033085e-02,  7.41281286e-02,  7.49596879e-02, ...,\n",
              "            8.40495974e-02, -1.03057846e-01,  9.16604549e-02],\n",
              "          [ 1.38588808e-02,  4.61337306e-02,  1.56972557e-02, ...,\n",
              "           -7.95739591e-02,  2.90854145e-02,  1.67301483e-02],\n",
              "          [ 4.07546908e-02,  4.93188947e-02, -5.71442097e-02, ...,\n",
              "            6.81271553e-02,  5.34514561e-02,  1.50011303e-02],\n",
              "          ...,\n",
              "          [ 4.45918553e-02,  4.55889478e-02,  9.71886143e-02, ...,\n",
              "           -9.77425128e-02,  1.16848107e-02, -3.19339894e-02],\n",
              "          [-5.39729260e-02, -9.42653418e-02,  3.20579893e-05, ...,\n",
              "            2.40821820e-02, -2.50867307e-02,  5.71361296e-02],\n",
              "          [-6.44677654e-02,  5.88495731e-02,  7.41720125e-02, ...,\n",
              "           -5.18983491e-02, -1.25304181e-02,  9.68781710e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 5.16659096e-02,  6.74883798e-02, -1.36489086e-02, ...,\n",
              "           -1.75601151e-02,  1.12257913e-01, -8.11671093e-02],\n",
              "          [-4.91021052e-02, -6.11576401e-02,  2.70491000e-02, ...,\n",
              "           -1.11394547e-01,  3.49706225e-02, -9.70017761e-02],\n",
              "          [-8.52152035e-02,  8.51520002e-02,  5.38800247e-02, ...,\n",
              "           -6.29511953e-04,  8.70885029e-02,  3.54813822e-02],\n",
              "          ...,\n",
              "          [-7.66690969e-02, -1.90303754e-02,  1.07723922e-01, ...,\n",
              "           -2.10368130e-02, -9.00450349e-02, -4.49593849e-02],\n",
              "          [-4.17747758e-02, -7.55469352e-02,  1.49719380e-02, ...,\n",
              "            6.08786009e-02, -1.00006931e-01,  3.98534350e-02],\n",
              "          [ 3.77333723e-02, -8.35006088e-02,  8.19832981e-02, ...,\n",
              "            6.59316853e-02, -8.15571770e-02, -1.04287036e-01]],\n",
              " \n",
              "         [[-3.73655334e-02, -7.47136846e-02,  2.74323206e-02, ...,\n",
              "            1.25702471e-02,  3.38103622e-02, -9.59700942e-02],\n",
              "          [-6.71572145e-03, -2.40006614e-02, -5.09362705e-02, ...,\n",
              "           -1.05313659e-01, -8.70311335e-02,  1.10357821e-01],\n",
              "          [-1.02841899e-01, -2.18034964e-02, -8.91405642e-02, ...,\n",
              "            1.08326033e-01, -1.08785301e-01, -9.41614732e-02],\n",
              "          ...,\n",
              "          [ 6.30274191e-02, -9.61375460e-02, -2.42103892e-03, ...,\n",
              "            1.05971612e-01, -1.11297138e-01,  5.29164821e-02],\n",
              "          [-5.73557951e-02,  4.23464514e-02, -1.42567540e-02, ...,\n",
              "            9.47221965e-02,  9.78620350e-02, -2.58145500e-02],\n",
              "          [-9.74343419e-02,  2.82071326e-02,  3.98492813e-02, ...,\n",
              "            1.10467747e-01,  6.63198829e-02,  4.83907014e-02]],\n",
              " \n",
              "         [[-7.30386749e-02, -2.86655258e-02, -7.09192827e-02, ...,\n",
              "            1.51711777e-02, -4.73968014e-02,  6.41543046e-02],\n",
              "          [-3.41057256e-02,  2.10479647e-02, -8.54126588e-02, ...,\n",
              "            3.45543623e-02,  6.85814247e-02,  1.24025464e-01],\n",
              "          [ 1.00969449e-01,  2.24790890e-02, -9.38848555e-02, ...,\n",
              "            2.23789853e-03, -2.91618221e-02, -1.35888383e-01],\n",
              "          ...,\n",
              "          [ 2.29242463e-02, -1.01738386e-01, -1.07342467e-01, ...,\n",
              "           -9.75531936e-02,  3.18637155e-02, -8.93937200e-02],\n",
              "          [-1.81215480e-02,  1.91136990e-02,  8.42717290e-02, ...,\n",
              "            3.64580005e-02, -1.02557682e-01, -3.55880447e-02],\n",
              "          [ 1.11606807e-01, -5.22074988e-03,  1.57397985e-01, ...,\n",
              "           -7.70103361e-04,  8.96929279e-02, -1.37487009e-01]]],\n",
              " \n",
              " \n",
              "        [[[-3.75021547e-02, -8.14770833e-02,  9.34332088e-02, ...,\n",
              "           -6.51981756e-02, -2.50890590e-02, -7.35236630e-02],\n",
              "          [-2.11240277e-02, -1.25921205e-01, -1.51840728e-02, ...,\n",
              "           -6.44354224e-02,  7.03454688e-02, -4.47159931e-02],\n",
              "          [ 2.67583262e-02, -3.63726076e-03, -1.19736329e-01, ...,\n",
              "            1.13741875e-01, -1.04393482e-01, -1.21628530e-01],\n",
              "          ...,\n",
              "          [-1.18432909e-01,  5.37473336e-02,  1.22003555e-01, ...,\n",
              "            5.86049408e-02,  1.12472184e-03,  8.45057666e-02],\n",
              "          [ 2.76573282e-02, -5.60224764e-02, -8.59261453e-02, ...,\n",
              "            9.75101590e-02, -9.47108567e-02,  2.01114155e-02],\n",
              "          [ 1.97366308e-02, -1.36754021e-01,  2.13039815e-02, ...,\n",
              "           -6.07254095e-02, -5.59253758e-03, -1.08362347e-01]],\n",
              " \n",
              "         [[ 5.64286634e-02, -6.57340437e-02, -3.68878245e-02, ...,\n",
              "            5.69954067e-02, -4.92383130e-02, -5.81721589e-02],\n",
              "          [-2.98439339e-02, -9.45860744e-02, -1.22478969e-01, ...,\n",
              "           -6.28257403e-04, -1.19794220e-01,  8.01131353e-02],\n",
              "          [-1.03225961e-01, -7.89777488e-02, -6.49736524e-02, ...,\n",
              "           -3.53054516e-02,  8.87731835e-02, -1.13304622e-01],\n",
              "          ...,\n",
              "          [-7.29857534e-02, -1.67611206e-03, -4.61693257e-02, ...,\n",
              "            2.36342624e-02, -5.67138009e-02, -4.51760292e-02],\n",
              "          [-6.53674826e-02, -3.42715494e-02, -7.52663836e-02, ...,\n",
              "            6.54904619e-02,  6.29234537e-02,  8.16696361e-02],\n",
              "          [ 1.31214842e-01,  5.34786358e-02, -3.33745703e-02, ...,\n",
              "           -4.26325090e-02, -7.54243582e-02,  1.15824312e-01]],\n",
              " \n",
              "         [[ 1.11125112e-01,  1.01429828e-01, -1.16499744e-01, ...,\n",
              "            3.05522103e-02,  5.63588366e-02,  6.73131198e-02],\n",
              "          [ 1.54080272e-01, -5.16495183e-02,  2.98427176e-02, ...,\n",
              "           -1.20669231e-02,  9.07440856e-02, -3.39989141e-02],\n",
              "          [-8.89778659e-02, -5.46107143e-02, -7.02809393e-02, ...,\n",
              "           -5.91156520e-02,  6.18842505e-02,  6.69723228e-02],\n",
              "          ...,\n",
              "          [-5.63479140e-02, -1.20906755e-01,  1.00659072e-01, ...,\n",
              "            9.02972594e-02,  2.39438824e-02,  5.93466423e-02],\n",
              "          [ 1.07284211e-01,  6.33074865e-02,  1.24702357e-01, ...,\n",
              "           -8.78540352e-02, -1.04588494e-01, -5.85562065e-02],\n",
              "          [-1.91071965e-02,  1.15744267e-02,  1.07139282e-01, ...,\n",
              "           -3.79298814e-02,  4.21969183e-02, -1.27088383e-01]]]],\n",
              "       dtype=float32),\n",
              " array([ 0.03288357,  0.01505632, -0.06782193,  0.01909896,  0.01717861,\n",
              "        -0.02274688,  0.01709301, -0.01742756, -0.00425142,  0.02391649,\n",
              "        -0.06666243, -0.05276591, -0.01167368, -0.01144856, -0.00560886,\n",
              "         0.00497083, -0.16695477,  0.101003  , -0.02595338,  0.02347036,\n",
              "         0.01751681, -0.08668034, -0.05582096, -0.03695821, -0.04803168,\n",
              "         0.04407259,  0.01553567, -0.06413537,  0.01473125,  0.03705617,\n",
              "        -0.04209346, -0.07996987], dtype=float32),\n",
              " array([[-0.00503957, -0.05370974, -0.07267353, ...,  0.00301343,\n",
              "          0.05629282,  0.00258503],\n",
              "        [-0.03400702,  0.03297027, -0.0185089 , ..., -0.05720658,\n",
              "         -0.05398707, -0.01191559],\n",
              "        [ 0.00025564,  0.04300629, -0.00279072, ..., -0.0080768 ,\n",
              "         -0.02535194,  0.04156009],\n",
              "        ...,\n",
              "        [ 0.00476009,  0.05702373,  0.05005748, ...,  0.06673166,\n",
              "         -0.05062146, -0.02261834],\n",
              "        [ 0.06519397, -0.04025346,  0.04366831, ..., -0.01623024,\n",
              "         -0.03292314,  0.0762153 ],\n",
              "        [ 0.05500294,  0.02188064, -0.02038089, ..., -0.03381859,\n",
              "          0.00991445, -0.07958535]], dtype=float32),\n",
              " array([ 7.20619503e-03, -7.64605729e-03, -1.43470587e-02, -1.21018514e-02,\n",
              "        -3.45273642e-03, -5.59761329e-03, -2.47191568e-03,  9.85737983e-03,\n",
              "        -1.03339748e-02,  1.72277987e-02, -9.68419109e-03,  1.22725796e-02,\n",
              "        -3.59382294e-03,  1.31854331e-02, -6.97940448e-03,  1.27277747e-02,\n",
              "         2.65083779e-02,  8.19725450e-03,  1.44933760e-02,  1.28280965e-03,\n",
              "        -1.91909145e-03,  1.57769993e-02,  1.00334221e-02, -1.47916842e-02,\n",
              "         1.72301400e-02, -1.16900532e-02,  1.49898743e-02, -1.15544954e-02,\n",
              "         9.89574706e-04, -8.34792946e-03,  8.52548052e-03,  4.33993846e-04,\n",
              "         1.94053780e-02, -5.44335414e-03,  3.53002138e-02,  3.44012608e-03,\n",
              "        -8.40578042e-03,  3.54868476e-03,  2.52848249e-02,  2.31401995e-02,\n",
              "         4.01256047e-03, -1.64366700e-02,  2.94380850e-04, -2.37360480e-03,\n",
              "        -2.51421612e-02, -9.20204679e-04,  3.67063680e-03,  4.75126598e-03,\n",
              "         6.67360891e-03,  0.00000000e+00, -8.71446077e-03, -2.65166815e-02,\n",
              "        -5.93146402e-03,  9.70090088e-03, -4.18902095e-03,  0.00000000e+00,\n",
              "         7.63087254e-03, -1.14507526e-02,  2.81999446e-02,  6.95560826e-03,\n",
              "         3.44571262e-03,  1.58359185e-02,  2.97292043e-02, -7.69355916e-04,\n",
              "         1.88306812e-02, -8.64011608e-03,  1.02152545e-02, -2.43985304e-03,\n",
              "         2.18316279e-02,  2.52771960e-03,  0.00000000e+00,  1.05645116e-02,\n",
              "        -6.52888743e-03, -5.56920236e-03,  1.24581697e-04, -1.34331528e-02,\n",
              "         2.29244549e-02, -7.17309595e-04,  1.39287207e-02,  1.80355664e-02,\n",
              "         2.20651571e-02, -6.38059853e-03,  3.59804183e-03, -1.95683762e-02,\n",
              "         6.87864237e-03,  1.35313654e-02,  0.00000000e+00, -1.24130547e-02,\n",
              "        -3.54087190e-03,  1.99443326e-04,  2.79879496e-02, -6.01331377e-03,\n",
              "        -3.54320335e-04,  4.07512905e-03,  1.97874680e-02,  0.00000000e+00,\n",
              "        -4.36726678e-03,  8.00015929e-04,  2.14793961e-02, -8.75983853e-03,\n",
              "         2.21487582e-02, -7.14496197e-03, -1.16219996e-02,  3.57243535e-03,\n",
              "        -1.91182531e-02, -2.70761736e-03,  5.09179384e-03,  1.73878819e-02,\n",
              "        -1.46585591e-02, -3.10993637e-03,  3.00499541e-03, -2.22472427e-03,\n",
              "        -1.91624777e-03,  2.28960328e-02,  5.06724136e-05, -1.73016265e-03,\n",
              "        -8.26522708e-03,  5.07376250e-03, -2.42721457e-02, -1.25744343e-02,\n",
              "        -6.34351629e-04,  3.07646990e-02, -2.15428136e-02,  1.37161035e-02,\n",
              "        -1.22044487e-02,  1.19454199e-02,  5.40870661e-03, -7.17246067e-03],\n",
              "       dtype=float32),\n",
              " array([[-0.14972858,  0.16741534, -0.1893567 , ..., -0.13807406,\n",
              "         -0.15544257,  0.061887  ],\n",
              "        [-0.11200935,  0.09760789,  0.03384753, ...,  0.1861506 ,\n",
              "         -0.2044506 , -0.01196696],\n",
              "        [ 0.23543671, -0.14389718, -0.08127707, ...,  0.02545767,\n",
              "         -0.11965746,  0.13107826],\n",
              "        ...,\n",
              "        [-0.17376904,  0.2397363 ,  0.22115357, ..., -0.03421467,\n",
              "         -0.12591122, -0.35131305],\n",
              "        [ 0.12848863,  0.1034984 , -0.03261227, ..., -0.230769  ,\n",
              "         -0.07156337, -0.06265797],\n",
              "        [-0.28381103, -0.04930405, -0.10126213, ...,  0.08659478,\n",
              "          0.20134927, -0.07977965]], dtype=float32),\n",
              " array([-0.07731614,  0.07129953, -0.01785564, -0.02363289,  0.01507555,\n",
              "         0.03635792, -0.03646539,  0.03397739, -0.00415328,  0.00271173],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdSgEiqWIOwt"
      },
      "source": [
        "## Part 2 - train a model\n",
        "\n",
        "A model's performance depends on many factors apart from the model architecture (e.g. type and number of layers) and the dataset. Here you will get to explore some of the factors that affect model performance. Much of the skill in training deep learning models lies in quickly finding good values/options for these choises.\n",
        "\n",
        "In order to observe the learning process it is best to compare the training set loss with the loss on the test set. How to visualize these variables with Keras is described under [Training history visualization](https://keras.io/visualization/#training-history-visualization) in the documentation.\n",
        "\n",
        "You will explore the effect of 1) optimizer, 2) training duration, and 3) dropout (see the question above).\n",
        "\n",
        "When training, an **epoch** is one pass through the full training set.\n",
        "\n",
        "### Question 3\n",
        "\n",
        "* **Vizualize the training**. Use the model above to observe the training process. Train it for 150 epochs and then plot both \"loss\" and \"val_loss\" (i.e. loss on the valiadtion set, here the terms \"validation set\" and \"test set\" are used interchangably, but this is not always true). What is the optimal number of epochs for minimizing the test set loss? \n",
        "    * Remember to first reset the weights (```model.reset_states()```), otherwise the training just continues from where it was stopped earlier.\n",
        "    \n",
        "    #answers are in the comment section but the optimal epoch number was 7 but i chose 50 to reduce total time to 1/3 from the original number of 150 epochs\n",
        "\n",
        "* **Optimizer**. Select three different optimizers and for each find the close-to-optimal hyper-parameter(s). In your answer, include a) your three choises, b) best hyper-parameters for each of the three optimizers and, c) the code that produced the results.\n",
        "    * *NOTE* that how long the training takes varies with optimizer. I.e., make sure that the model is trained for long enough to reach optimal performance.\n",
        "    a) i chose sgd, adam,adagrad, and adamax b) the best hyperparameter was learning rate of 0.01, learnig rate only changed the accuracy for adagrad and adamax and for sgd and adam it was the same for 0.01,0.02,0.03 and 0.04. Adamax produced a higher accuracy than all of them and this was when learning rate was 0.01 and the code is below\n",
        "\n",
        "* **Dropout**. Use the best optimizer and do hyper-parameter seach and find the best value for ```Dropout()```.\n",
        "#The best value for dropout is 0.5 as shown in the code below. I tested it with 0,0.5,0.6,0.7, and 0.8.\n",
        "\n",
        "* **Best model**. Combine the what you learned from the above three questions to build the best model. How much better is it than the worst and average models?\n",
        "\n",
        "    <span style=\"color:red\"> < #it is better than the average models by giving a better accuracy of  1-4% depending on each optimizer. The worst model was adamax dropout rate of 0.8, it had accuracy of 92% and was worse than the models with different optimizers as they all had accuracy rates of 92.5% of higher. The best model is in the comments in the end, it is adamax, learning rate 0.01 and dropout of 0.5.  *> </span>\n",
        "\n",
        "\n",
        "* **Results on the test set**. When doing this search for good model configuration/hyper-parameter values, the data set was split into *two* parts: a training set and a test set (the term \"validation\" was used interchangably wiht \"test\"). For your final model, is the performance (i.e. accuracy) on the test set representative for the performance one would expect on a previously unseen data set (drawn from the same distribution)? Why?\n",
        "\n",
        "    <span style=\"color:red\"> <yes because we reset our weights, the validation data is not biased as the evaluation of the training data would result in a biased score. also the model was not trained on the test set it was only trained on the training set, so test set would be the same as previously unseen data> </span>\n",
        "\n",
        "\n",
        "## Further information\n",
        "For ideas about hyper-parameter tuning, take a look at the strategies described in the sklearn documentation under [model selection](https://scikit-learn.org/stable/model_selection.html), or in this [blog post](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html) from TensorFlow. For a more thorough discussion about optimizers see [this video](https://www.youtube.com/watch?v=DiNzQP7kK-s) discussing the article [Descending through a Crowded Valley -- Benchmarking Deep Learning Optimizers](https://arxiv.org/abs/2007.01547).\n",
        "\n",
        "\n",
        "**Good luck!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhtjAl54IOwx"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1VW9lMoIOw0",
        "outputId": "af3c78f2-a8df-4f7c-f9b4-e135c959e923"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=150,validation_data=(X_test,y_oh_test))\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "25/25 [==============================] - 2s 35ms/step - loss: 2.2317 - accuracy: 0.2057 - val_loss: 1.7812 - val_accuracy: 0.4750\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2515 - accuracy: 0.6636 - val_loss: 0.7918 - val_accuracy: 0.7450\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.5384 - accuracy: 0.8148 - val_loss: 0.4853 - val_accuracy: 0.8550\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3447 - accuracy: 0.8993 - val_loss: 0.3674 - val_accuracy: 0.8850\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2615 - accuracy: 0.9190 - val_loss: 0.4285 - val_accuracy: 0.8700\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2047 - accuracy: 0.9271 - val_loss: 0.3760 - val_accuracy: 0.8950\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1651 - accuracy: 0.9522 - val_loss: 0.3550 - val_accuracy: 0.8950\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1485 - accuracy: 0.9434 - val_loss: 0.3529 - val_accuracy: 0.9000\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0979 - accuracy: 0.9649 - val_loss: 0.3090 - val_accuracy: 0.9100\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0639 - accuracy: 0.9760 - val_loss: 0.3689 - val_accuracy: 0.9100\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0474 - accuracy: 0.9886 - val_loss: 0.3795 - val_accuracy: 0.8900\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0599 - accuracy: 0.9808 - val_loss: 0.3364 - val_accuracy: 0.9150\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0428 - accuracy: 0.9899 - val_loss: 0.3403 - val_accuracy: 0.9250\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0256 - accuracy: 0.9964 - val_loss: 0.3973 - val_accuracy: 0.9050\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0188 - accuracy: 0.9992 - val_loss: 0.3389 - val_accuracy: 0.9150\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0234 - accuracy: 0.9968 - val_loss: 0.3866 - val_accuracy: 0.9150\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0286 - accuracy: 0.9918 - val_loss: 0.3161 - val_accuracy: 0.9150\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.3823 - val_accuracy: 0.9300\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0134 - accuracy: 0.9999 - val_loss: 0.3502 - val_accuracy: 0.9250\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0115 - accuracy: 0.9983 - val_loss: 0.3836 - val_accuracy: 0.9200\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9250\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9250\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9200\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9200\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9200\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9200\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9200\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9200\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9200\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9200\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9200\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9250\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9200\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9200\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9250\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.3415e-04 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9250\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9250\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9200\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.9200\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.3410e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9250\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.6872e-04 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9200\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.5791e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9250\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.7689e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9250\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.5947e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9250\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.4830e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9250\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.8851e-04 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9250\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.2986e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9250\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.6307e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9250\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.5481e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9250\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.9640e-04 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9250\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.6811e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9250\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.9593e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9250\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.0698e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9250\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.2302e-04 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9250\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.3038e-04 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.9250\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.3443e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9250\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.3808e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9250\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.5303e-04 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9250\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.4999e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9250\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.0920e-04 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9250\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 4.8508e-04 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9250\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 4.4040e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9250\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 4.5940e-04 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9250\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 4.3047e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9250\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.9457e-04 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9250\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.7845e-04 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9250\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.6299e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9250\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.6258e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9250\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.7528e-04 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.9250\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.6458e-04 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9250\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.5481e-04 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9250\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 4.6023e-04 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9250\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.9922e-04 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9250\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.6095e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9250\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.1970e-04 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9250\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.1106e-04 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.9250\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.3753e-04 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9250\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.8034e-04 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9250\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.5289e-04 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9250\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.1732e-04 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9250\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.6781e-04 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9250\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.6129e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9250\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.0535e-04 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9250\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.4093e-04 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9250\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.4976e-04 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9250\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.9608e-04 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9250\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.7439e-04 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9250\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.8048e-04 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9250\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.9082e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9250\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.6746e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9250\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.4771e-04 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9250\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.8655e-04 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9250\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.6967e-04 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9250\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.4413e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9250\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.6805e-04 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9250\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2225e-04 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9250\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.6269e-04 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9250\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2973e-04 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9250\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.3297e-04 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9250\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.1458e-04 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9250\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.2057e-04 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9250\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.7613e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9250\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.5485e-04 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9250\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.6562e-04 - accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 0.9250\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.4901e-04 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9250\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.9460e-04 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9250\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.3687e-04 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.9250\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.5474e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9250\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2027e-04 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9250\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 2.0923e-04 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.9250\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.4542e-04 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9250\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.0766e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9250\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.8396e-04 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9250\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.0962e-04 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9250\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.8464e-04 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9250\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.2208e-04 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9250\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.7955e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9250\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2046e-04 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9250\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.7646e-04 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9250\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.7616e-04 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9250\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.7594e-04 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.9250\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.8942e-04 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9250\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.9990e-04 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9250\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.1552e-04 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9250\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.6367e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9250\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.9133e-04 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9250\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.6031e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9250\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.7155e-04 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.9250\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.7967e-04 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9250\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.6439e-04 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.9250\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.5626e-04 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9250\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.7905e-04 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9250\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.5702e-04 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9250\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.7246e-04 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.9250\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.6825e-04 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.9250\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.5980e-04 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.9250\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.6563e-04 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9250\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.4875e-04 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9250\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.6187e-04 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9250\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.5415e-04 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9250\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.8778e-04 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.9250\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.5197e-04 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.9250\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.5294e-04 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9250\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.7046e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9250\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.4576e-04 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9250\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3812e-04 - accuracy: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.9250\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.6122e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9250\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.4461e-04 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.9250\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.3326e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9250\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.4579e-04 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9250\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5022 - accuracy: 0.9250\n",
            "Accuracy: 0.925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xbaiMdoIOw1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OP6T6qIIOw2"
      },
      "source": [
        "# if we increase number of epochs, we get longer training time\n",
        "#for dropout,it makes the other neurons equally efficient, less connections = faster training time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id9UybQ_IOw3"
      },
      "source": [
        "w=model.get_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lrHB8EJ1IOw3",
        "outputId": "0ef13293-9074-4060-d5df-431066e66550"
      },
      "source": [
        "w"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[[-0.13357006,  0.548377  ,  0.21996218,  0.03071775,\n",
              "            0.44445854,  0.17814417,  0.03605998, -0.09688392,\n",
              "            0.20033245,  0.13575324, -0.18022594,  0.12296428,\n",
              "           -0.01507076, -0.00195981,  0.595177  , -0.16259995]],\n",
              " \n",
              "         [[ 0.13658243,  0.44457173, -0.03829726, -0.00226709,\n",
              "            0.27973342,  0.12526813,  0.18981713,  0.01298683,\n",
              "            0.25584617,  0.15164559,  0.20975398,  0.1763876 ,\n",
              "            0.06520469,  0.32175222,  0.28765664, -0.05920264]],\n",
              " \n",
              "         [[ 0.27827734,  0.14911713, -0.19898559, -0.1427354 ,\n",
              "            0.20796879, -0.02251739,  0.0032203 , -0.05226165,\n",
              "           -0.12683988, -0.22708414,  0.41495207,  0.22650738,\n",
              "            0.01685571,  0.34851494,  0.5552751 , -0.05641799]]],\n",
              " \n",
              " \n",
              "        [[[-0.18522076,  0.4418405 ,  0.26668423,  0.35706583,\n",
              "            0.42352954, -0.04446587, -0.12935868,  0.05291915,\n",
              "            0.37218857,  0.1743184 , -0.157042  ,  0.33966148,\n",
              "            0.01309635, -0.0361598 ,  0.7691457 ,  0.03184742]],\n",
              " \n",
              "         [[ 0.03311905,  0.12372736,  0.1904656 ,  0.63160646,\n",
              "            0.34286675, -0.14434429, -0.01940831, -0.13046446,\n",
              "           -0.0384682 ,  0.34426776,  0.26579484, -0.04276262,\n",
              "           -0.00606765,  0.25502092,  0.84054136, -0.18297519]],\n",
              " \n",
              "         [[ 0.2755451 ,  0.06166823,  0.14945263,  0.489885  ,\n",
              "            0.01489705, -0.07610614,  0.36235917,  0.05596768,\n",
              "           -0.10545753,  0.02821092,  0.09255706,  0.01815362,\n",
              "           -0.09017642,  0.30426255,  0.58329177, -0.10472218]]],\n",
              " \n",
              " \n",
              "        [[[ 0.06456902,  0.39665347,  0.10158017,  0.61971545,\n",
              "           -0.03663061,  0.2862898 ,  0.33642098,  0.0848942 ,\n",
              "            0.3727212 ,  0.09302808,  0.2615104 ,  0.2327461 ,\n",
              "            0.23621148,  0.00892944,  0.5464752 ,  0.33505535]],\n",
              " \n",
              "         [[-0.09376761,  0.29315907,  0.32733202,  0.5468936 ,\n",
              "            0.158701  ,  0.28926882,  0.4532313 , -0.14879334,\n",
              "            0.1483895 ,  0.32128483,  0.33398336,  0.27060413,\n",
              "            0.29474154,  0.04070406,  0.42981565,  0.19315767]],\n",
              " \n",
              "         [[ 0.03495206, -0.04989063,  0.12031315,  0.57499313,\n",
              "            0.1592926 ,  0.18869981,  0.55533564,  0.15239605,\n",
              "            0.2142038 ,  0.21467762,  0.37285998,  0.09412567,\n",
              "            0.23361912,  0.06733456,  0.09006583,  0.02619713]]]],\n",
              "       dtype=float32),\n",
              " array([ 5.23015216e-04, -6.32324666e-02,  5.19318366e-03,  6.60570478e-03,\n",
              "        -5.06739616e-02, -5.73031083e-02, -6.54109335e-03,  5.48207685e-02,\n",
              "        -8.55864142e-04,  2.28350167e-03,  6.41895807e-04,  7.82030344e-04,\n",
              "        -3.56496163e-02,  2.48405536e-06, -3.65002789e-02,  1.07061215e-01],\n",
              "       dtype=float32),\n",
              " array([[[[ 1.34862527e-01, -1.06724583e-01,  9.58975926e-02, ...,\n",
              "           -4.38975263e-03, -2.87107546e-02,  9.97654200e-02],\n",
              "          [-4.26178314e-02, -7.78508708e-02,  8.56175646e-02, ...,\n",
              "            7.75601640e-02, -1.59406990e-01,  2.76140589e-02],\n",
              "          [-3.07910610e-03,  1.02262735e-01,  2.65132263e-02, ...,\n",
              "            1.24470890e-01,  3.42531838e-02, -1.34964943e-01],\n",
              "          ...,\n",
              "          [ 3.19280312e-03, -1.83275491e-02, -1.72425285e-02, ...,\n",
              "           -8.32422152e-02, -7.98165724e-02, -3.60941561e-03],\n",
              "          [ 2.74932794e-02, -1.15095070e-02,  1.71231832e-02, ...,\n",
              "            1.77012324e-01, -2.38526285e-01,  7.33295381e-02],\n",
              "          [-1.16332941e-01,  1.26347644e-02, -5.26216365e-02, ...,\n",
              "            1.35654230e-02, -1.45892411e-01,  5.11240885e-02]],\n",
              " \n",
              "         [[-6.68754205e-02, -5.28302844e-05,  8.42222571e-02, ...,\n",
              "           -1.87157895e-02,  9.66528282e-02,  1.05841137e-01],\n",
              "          [ 1.77841619e-01,  8.95338412e-03,  1.59112792e-02, ...,\n",
              "            1.60668343e-01,  9.12362784e-02,  7.13872835e-02],\n",
              "          [-8.59462768e-02, -9.86115709e-02, -7.31764212e-02, ...,\n",
              "           -4.77988869e-02, -5.39649650e-02,  7.85415694e-02],\n",
              "          ...,\n",
              "          [ 8.37843865e-02, -1.17625661e-01, -4.98462170e-02, ...,\n",
              "            3.56619395e-02, -7.80446967e-03,  9.97210816e-02],\n",
              "          [-4.89466786e-02, -1.27617016e-01,  1.70967728e-02, ...,\n",
              "            1.26423031e-01,  1.41241580e-01,  9.73905027e-02],\n",
              "          [-4.65272032e-02,  1.19368806e-01, -9.30480361e-02, ...,\n",
              "            2.93227322e-02,  6.46613771e-04,  2.33480744e-02]],\n",
              " \n",
              "         [[-4.43613157e-03, -1.19763061e-01,  9.48846340e-03, ...,\n",
              "            4.90980456e-03, -6.90350160e-02,  3.02939471e-02],\n",
              "          [ 6.84227347e-02, -2.87150797e-02,  1.29943401e-01, ...,\n",
              "            3.92117910e-02,  8.48500431e-02, -1.22987367e-02],\n",
              "          [ 1.11643419e-01, -4.84746397e-02, -3.25429589e-02, ...,\n",
              "           -7.49548972e-02,  1.07189074e-01, -1.79366451e-02],\n",
              "          ...,\n",
              "          [-3.06200348e-02, -9.03508514e-02,  4.92403377e-03, ...,\n",
              "            1.60299376e-01,  1.51927453e-02,  8.92197639e-02],\n",
              "          [-1.39994159e-01, -1.81775227e-01,  7.93150365e-02, ...,\n",
              "            1.21379711e-01,  2.42962152e-01, -3.47156599e-02],\n",
              "          [ 8.64206031e-02,  1.66423712e-02, -7.32102841e-02, ...,\n",
              "           -1.14241771e-01, -1.12089127e-01, -5.82847632e-02]]],\n",
              " \n",
              " \n",
              "        [[[ 9.90362912e-02, -3.30132134e-02, -7.44355693e-02, ...,\n",
              "           -9.56155825e-03, -7.71913752e-02, -2.48793140e-02],\n",
              "          [ 4.46826443e-02,  5.54395281e-02, -8.82556736e-02, ...,\n",
              "           -3.00545078e-02, -1.04739487e-01, -6.95208162e-02],\n",
              "          [-6.64210021e-02,  4.12271619e-02,  1.08262956e-01, ...,\n",
              "           -3.85128111e-02,  1.07062785e-02,  8.07342678e-02],\n",
              "          ...,\n",
              "          [ 1.38871744e-01, -2.51113810e-02, -1.07658774e-01, ...,\n",
              "            2.05323473e-02,  4.29124869e-02, -3.34793446e-03],\n",
              "          [ 1.87229365e-01,  1.93408608e-01, -8.29881877e-02, ...,\n",
              "           -7.24602938e-02, -2.12850139e-01, -4.20496389e-02],\n",
              "          [ 9.69224349e-02, -7.81518072e-02, -3.00075337e-02, ...,\n",
              "            7.39510506e-02,  8.06214809e-02,  4.45965007e-02]],\n",
              " \n",
              "         [[-4.42999192e-02, -7.17906058e-02, -3.31915468e-02, ...,\n",
              "           -8.59139413e-02, -1.53604224e-02, -7.35340193e-02],\n",
              "          [-2.45090034e-02,  2.68841302e-03,  9.75598916e-02, ...,\n",
              "            8.04060623e-02,  3.69647853e-02, -4.13620509e-02],\n",
              "          [ 5.36627583e-02,  1.23578191e-01, -5.23275211e-02, ...,\n",
              "           -1.00010917e-01,  3.83898020e-02, -8.21616054e-02],\n",
              "          ...,\n",
              "          [-4.83645909e-02, -8.10252279e-02,  6.12159893e-02, ...,\n",
              "            9.85679105e-02,  1.13802701e-02, -7.99351409e-02],\n",
              "          [ 1.55703157e-01,  7.83773661e-02, -7.77633563e-02, ...,\n",
              "            1.03607208e-01,  2.22166609e-02, -3.33627202e-02],\n",
              "          [-1.92773454e-02, -3.23236734e-02, -3.17627639e-02, ...,\n",
              "           -4.57697250e-02, -5.97627982e-02, -4.09503840e-02]],\n",
              " \n",
              "         [[ 7.42758736e-02, -2.45695673e-02, -4.69382219e-02, ...,\n",
              "           -7.29166046e-02,  5.47059402e-02,  3.11565585e-02],\n",
              "          [ 7.04709068e-02,  1.48632407e-01,  1.18955858e-01, ...,\n",
              "            3.82873304e-02,  1.26495481e-01, -1.53028324e-01],\n",
              "          [ 1.20347582e-01,  1.39002018e-02,  4.71817283e-03, ...,\n",
              "           -1.58008561e-02, -6.33254051e-02,  9.44478363e-02],\n",
              "          ...,\n",
              "          [ 8.54714513e-02,  1.00838870e-01, -6.19451776e-02, ...,\n",
              "           -6.89387694e-02,  3.09922080e-02, -1.24416143e-01],\n",
              "          [ 2.33248062e-02, -2.26871390e-02, -5.45277819e-02, ...,\n",
              "            7.92209208e-02,  2.00183943e-01, -9.54825059e-03],\n",
              "          [-1.40834730e-02,  4.20163423e-02,  1.04152776e-01, ...,\n",
              "            8.88139158e-02, -1.01828188e-01,  1.33048669e-01]]],\n",
              " \n",
              " \n",
              "        [[[-8.69389176e-02,  1.23625457e-01,  1.08952925e-01, ...,\n",
              "           -4.90618944e-02, -6.26729950e-02,  9.62285474e-02],\n",
              "          [-6.92349160e-03, -1.01113409e-01, -3.31239961e-02, ...,\n",
              "           -5.07478006e-02,  1.06569715e-02,  2.57571880e-02],\n",
              "          [ 1.25101238e-01, -1.19818434e-01, -1.81981467e-03, ...,\n",
              "           -7.05089942e-02, -1.01325542e-01, -6.99505731e-02],\n",
              "          ...,\n",
              "          [-6.78817853e-02,  3.50232832e-02,  1.18550519e-02, ...,\n",
              "            7.11131543e-02, -1.04453012e-01,  1.27128035e-01],\n",
              "          [ 1.37373000e-01, -1.42338052e-01, -8.83847773e-02, ...,\n",
              "           -4.92471159e-02,  8.68691951e-02,  8.26397985e-02],\n",
              "          [ 8.97982493e-02, -1.33567164e-02,  4.32766415e-02, ...,\n",
              "            1.21963145e-02,  9.70058665e-02,  2.20775306e-02]],\n",
              " \n",
              "         [[ 5.34915887e-02, -6.82018772e-02, -1.08149685e-01, ...,\n",
              "           -1.19519658e-01,  1.53104905e-02, -1.01613909e-01],\n",
              "          [ 1.02348693e-01,  9.91160795e-02, -5.92789911e-02, ...,\n",
              "           -1.37303740e-01,  1.15356557e-01,  7.51424907e-03],\n",
              "          [-8.04215074e-02,  1.25741521e-02,  9.40465555e-02, ...,\n",
              "           -1.49439480e-02, -2.05088910e-02,  9.53769311e-02],\n",
              "          ...,\n",
              "          [-4.93743457e-03,  1.28429011e-01,  4.92632911e-02, ...,\n",
              "           -5.70445210e-02,  1.41558111e-01, -3.11016683e-02],\n",
              "          [-3.38033624e-02,  1.54524008e-02,  7.49016181e-02, ...,\n",
              "           -8.47206637e-02,  1.91805080e-01,  1.48210460e-02],\n",
              "          [ 6.88668489e-02,  4.18252125e-02, -1.12079531e-01, ...,\n",
              "           -3.78783755e-02,  7.41955712e-02,  1.12876512e-01]],\n",
              " \n",
              "         [[ 2.33715195e-02, -1.01492286e-01, -4.81323004e-02, ...,\n",
              "            4.69501279e-02,  6.99036717e-02, -1.03494667e-01],\n",
              "          [ 5.94062172e-02,  6.37717023e-02,  4.65115830e-02, ...,\n",
              "           -1.38078228e-01,  1.97469100e-01,  8.57103318e-02],\n",
              "          [ 6.82774931e-02,  1.20300464e-01,  2.30781850e-03, ...,\n",
              "            4.46219034e-02, -3.09377126e-02,  1.53536081e-01],\n",
              "          ...,\n",
              "          [-2.12141480e-02,  2.91473363e-02,  8.29803571e-02, ...,\n",
              "            4.80569676e-02, -4.15461063e-02,  1.32485539e-01],\n",
              "          [-7.21877664e-02, -4.48968783e-02, -1.01650037e-01, ...,\n",
              "           -1.85375139e-01,  7.61837885e-02, -3.35208466e-03],\n",
              "          [-1.09039377e-02, -4.83873449e-02,  8.07480440e-02, ...,\n",
              "            6.08174838e-02, -1.12193920e-01,  1.20458558e-01]]]],\n",
              "       dtype=float32),\n",
              " array([-0.09532276, -0.01806784,  0.00799799,  0.0982497 , -0.06643538,\n",
              "        -0.12236024, -0.06366933,  0.04024532, -0.0300334 , -0.065087  ,\n",
              "        -0.11415682, -0.07464004, -0.00863831, -0.03009984, -0.01681721,\n",
              "        -0.10413747, -0.01912761,  0.05733748, -0.11343093, -0.02306442,\n",
              "        -0.03803376,  0.03238255,  0.06032128,  0.00505284,  0.05740243,\n",
              "        -0.05813492,  0.00351181,  0.00487839, -0.08659486,  0.07624851,\n",
              "        -0.08987334,  0.01583388], dtype=float32),\n",
              " array([[-0.05845282,  0.06933652, -0.01325841, ..., -0.02341333,\n",
              "          0.07963692,  0.05945038],\n",
              "        [-0.06005334, -0.08221886, -0.00539627, ..., -0.00140101,\n",
              "         -0.00583781,  0.07684808],\n",
              "        [ 0.04492118, -0.06296117, -0.07421314, ..., -0.01870433,\n",
              "         -0.01206735,  0.01677631],\n",
              "        ...,\n",
              "        [ 0.01726814,  0.04770126, -0.04753742, ..., -0.03150203,\n",
              "         -0.03133994,  0.04536366],\n",
              "        [-0.07707702, -0.0242403 , -0.03211625, ..., -0.01834449,\n",
              "         -0.04855857,  0.02764522],\n",
              "        [ 0.05845984, -0.01876785,  0.04598146, ..., -0.01119187,\n",
              "         -0.04348429, -0.0618486 ]], dtype=float32),\n",
              " array([ 9.4578182e-03, -1.5555112e-02, -4.5120977e-03,  1.6453503e-02,\n",
              "         4.4769319e-04,  8.8877520e-03,  2.8417581e-03,  4.2377785e-03,\n",
              "         1.8444497e-03, -3.8601260e-03, -3.1342772e-03, -8.0628023e-03,\n",
              "         6.4074835e-03, -1.6375797e-02,  1.1216198e-02,  4.5947339e-03,\n",
              "         5.7560168e-03, -9.4564669e-03, -1.0846598e-02, -5.3024595e-03,\n",
              "         3.1826163e-03, -1.7544931e-02, -1.3434424e-02,  2.2638876e-02,\n",
              "        -5.5159880e-03,  0.0000000e+00, -3.5297531e-03, -2.1602931e-04,\n",
              "         7.7179464e-04,  6.3611497e-03,  1.1637792e-02, -1.8264083e-04,\n",
              "         6.2139044e-03, -8.3744824e-03,  4.2648133e-02,  1.2248177e-04,\n",
              "        -1.3901125e-02,  2.2271952e-02,  1.5402335e-02,  2.5096184e-02,\n",
              "         1.4662922e-03,  2.0869259e-02, -5.3219055e-04,  7.9338215e-03,\n",
              "        -8.6962292e-03, -1.6164308e-04, -1.1895272e-02,  2.0400479e-02,\n",
              "         1.0346024e-03,  0.0000000e+00,  1.7394746e-02,  1.2766734e-02,\n",
              "        -1.7887322e-02,  0.0000000e+00, -1.8022157e-02,  0.0000000e+00,\n",
              "         4.3844301e-03,  3.8232361e-03, -4.0950249e-03,  1.2646131e-02,\n",
              "         1.3570394e-04,  3.5040386e-02,  2.2755924e-03,  1.7062975e-04,\n",
              "        -4.4378736e-03,  0.0000000e+00,  1.6216090e-02, -1.7204726e-02,\n",
              "         1.5000683e-02,  2.2041244e-02,  1.7062923e-02,  9.0762129e-04,\n",
              "         3.4790791e-03,  8.7340204e-03, -1.0747002e-03,  2.4017910e-02,\n",
              "         2.4529928e-02,  0.0000000e+00, -2.2294560e-05,  1.3952382e-02,\n",
              "        -8.1775397e-05,  1.0204297e-02, -1.3143145e-03,  1.2679419e-02,\n",
              "        -1.4481644e-04, -1.5874314e-03,  9.2263799e-03,  3.5539479e-03,\n",
              "         8.2614971e-03,  1.2252279e-02,  1.8551115e-02,  4.6619079e-03,\n",
              "         8.2710637e-03,  6.1424556e-03,  6.6803717e-03, -1.2788458e-02,\n",
              "        -5.4813721e-03,  8.9904079e-03,  9.2327101e-03, -2.4223942e-03,\n",
              "        -3.9860215e-03,  1.5573398e-02, -4.5572626e-03,  4.3116049e-03,\n",
              "        -1.1596520e-02,  2.2073437e-03, -5.0339843e-03,  0.0000000e+00,\n",
              "         3.2456413e-02, -2.2394701e-03,  2.3859136e-03, -4.1913900e-05,\n",
              "         9.2976708e-03,  1.1662245e-02,  1.7952673e-02, -9.5422771e-03,\n",
              "        -4.6722847e-03,  6.5602693e-03,  2.1617357e-02,  7.3919725e-04,\n",
              "        -4.0884642e-03, -1.2652498e-02,  1.6790871e-02,  1.0191440e-02,\n",
              "         2.9359334e-03, -3.9154114e-03,  1.6241020e-02, -1.5271000e-03],\n",
              "       dtype=float32),\n",
              " array([[-0.11912914,  0.09964817,  0.06246721, ..., -0.01863737,\n",
              "         -0.14254914, -0.09248231],\n",
              "        [ 0.21553141, -0.19475555,  0.16674866, ..., -0.11957476,\n",
              "          0.23574722,  0.22964062],\n",
              "        [ 0.1533772 , -0.07132833,  0.11987461, ..., -0.12815832,\n",
              "         -0.05639076, -0.19396225],\n",
              "        ...,\n",
              "        [ 0.15667728, -0.1242962 ,  0.0110152 , ..., -0.12135628,\n",
              "         -0.08052297, -0.19544156],\n",
              "        [-0.20841533,  0.19027229,  0.1581097 , ...,  0.13888967,\n",
              "         -0.13358897, -0.1626752 ],\n",
              "        [ 0.05856958, -0.04882804, -0.08134283, ...,  0.16545692,\n",
              "          0.07683675,  0.20599782]], dtype=float32),\n",
              " array([-0.06170207,  0.06016321, -0.00956235, -0.03923968,  0.01855577,\n",
              "         0.00636656,  0.00508853,  0.01194447, -0.02530419,  0.03368629],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guc2U47SIOw4",
        "outputId": "4cccebcc-c98b-4923-e127-09534bc7bc48"
      },
      "source": [
        "w[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 3, 1, 16)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1JnQo_aIOw8",
        "outputId": "d4455442-72a5-486b-e483-9ec8ae9ed769"
      },
      "source": [
        "test_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5022115111351013, 0.925000011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RojnG0cIOw_",
        "outputId": "8d734dde-1588-436f-b87a-ffeb71dc6f89"
      },
      "source": [
        "model.metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.metrics.Mean at 0x1bfb87a6dd8>,\n",
              " <tensorflow.python.keras.metrics.MeanMetricWrapper at 0x1bfc08739e8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d87mhWoKIOxA"
      },
      "source": [
        "model.metrics_names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVc9NmKRIOxB",
        "outputId": "bf071fb6-ed5b-4939-b8f1-72a44bdaab7f"
      },
      "source": [
        "model.metrics_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['loss', 'accuracy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct3EVg4FIOxC",
        "outputId": "08f609c4-2ddd-4a2c-9a5c-3796008f4a63"
      },
      "source": [
        "history.history.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QobxZMtzIOxD",
        "outputId": "7f166015-a549-4334-dac5-6c582533d596"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train','val'],loc='upper left')\n",
        "plt.show()\n",
        "np.argmin(history.history['val_loss'])\n",
        "#this shows that valuation loss is lowest when epoch is 7, we will train the data with 50 epochs to reduce time to 1/3 of the original time although we know we can train with 7."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ebj3F3YZIOxE",
        "outputId": "cb4c9e84-1026-4a65-d624-de6dfffa0743"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['validation','val'],loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OD9d0Z-IOxF",
        "outputId": "0d3a6fab-291b-46ff-ec01-660e39fcca21"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['test','val'],loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeOByun8IOxG",
        "outputId": "20187856-2492-40cc-c42f-2d805e78da4a"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [2.127877950668335,\n",
              "  1.027855634689331,\n",
              "  0.5010098814964294,\n",
              "  0.33155113458633423,\n",
              "  0.247364804148674,\n",
              "  0.22277076542377472,\n",
              "  0.16693542897701263,\n",
              "  0.13048715889453888,\n",
              "  0.10185469686985016,\n",
              "  0.07625922560691833,\n",
              "  0.056064724922180176,\n",
              "  0.05615031719207764,\n",
              "  0.03810036554932594,\n",
              "  0.027418266981840134,\n",
              "  0.021508341655135155,\n",
              "  0.021130509674549103,\n",
              "  0.023131821304559708,\n",
              "  0.015378790907561779,\n",
              "  0.012693231925368309,\n",
              "  0.010498175397515297,\n",
              "  0.004956187680363655,\n",
              "  0.003436090424656868,\n",
              "  0.002808019518852234,\n",
              "  0.002335804281756282,\n",
              "  0.002049956703558564,\n",
              "  0.001928057987242937,\n",
              "  0.0017368794651702046,\n",
              "  0.0016324195312336087,\n",
              "  0.0014825701946392655,\n",
              "  0.001401202636770904,\n",
              "  0.0013289654161781073,\n",
              "  0.0012745850253850222,\n",
              "  0.0012078597210347652,\n",
              "  0.0011468894081190228,\n",
              "  0.001087456475943327,\n",
              "  0.0010502781951799989,\n",
              "  0.00098477303981781,\n",
              "  0.0009500230080448091,\n",
              "  0.0009093077387660742,\n",
              "  0.0008626453345641494,\n",
              "  0.0008551792125217617,\n",
              "  0.0008183308527804911,\n",
              "  0.0007834230200387537,\n",
              "  0.000759781280066818,\n",
              "  0.0007315954426303506,\n",
              "  0.0007099448121152818,\n",
              "  0.0006960225873626769,\n",
              "  0.0006766850710846484,\n",
              "  0.0006476544076576829,\n",
              "  0.0006296659121289849,\n",
              "  0.0006144539802335203,\n",
              "  0.0005932491039857268,\n",
              "  0.000577095546759665,\n",
              "  0.0005673639825545251,\n",
              "  0.0005506674060598016,\n",
              "  0.0005378823261708021,\n",
              "  0.0005226132925599813,\n",
              "  0.0005128372577019036,\n",
              "  0.0004990848246961832,\n",
              "  0.0004866041708737612,\n",
              "  0.000477449968457222,\n",
              "  0.00046680239029228687,\n",
              "  0.0004565235576592386,\n",
              "  0.00044805306242778897,\n",
              "  0.0004345139896031469,\n",
              "  0.0004265345633029938,\n",
              "  0.00042406993452459574,\n",
              "  0.0004112041788175702,\n",
              "  0.00040399300632998347,\n",
              "  0.0003978308232035488,\n",
              "  0.000389015709515661,\n",
              "  0.0003788061148952693,\n",
              "  0.000375776959117502,\n",
              "  0.00037000735756009817,\n",
              "  0.0003600277123041451,\n",
              "  0.0003534439601935446,\n",
              "  0.0003476566926110536,\n",
              "  0.0003443238965701312,\n",
              "  0.00033974871621467173,\n",
              "  0.00033148328657262027,\n",
              "  0.00032560343970544636,\n",
              "  0.00032192759681493044,\n",
              "  0.0003164309891872108,\n",
              "  0.00031002479954622686,\n",
              "  0.0003043675678782165,\n",
              "  0.0003021417651325464,\n",
              "  0.0002972545044030994,\n",
              "  0.00029359772452153265,\n",
              "  0.0002875818172469735,\n",
              "  0.00028230430325493217,\n",
              "  0.0002796831540763378,\n",
              "  0.000274857971817255,\n",
              "  0.00027194220456294715,\n",
              "  0.00026890335720963776,\n",
              "  0.0002647926448844373,\n",
              "  0.0002612409880384803,\n",
              "  0.0002577184932306409,\n",
              "  0.00025362070300616324,\n",
              "  0.0002503868017811328,\n",
              "  0.00024779606610536575,\n",
              "  0.0002431585016893223,\n",
              "  0.0002418676158413291,\n",
              "  0.00023888771829660982,\n",
              "  0.00023478064395021647,\n",
              "  0.00023142914869822562,\n",
              "  0.0002288316609337926,\n",
              "  0.0002269339165650308,\n",
              "  0.0002246350923087448,\n",
              "  0.0002207712095696479,\n",
              "  0.00021893874509260058,\n",
              "  0.0002165306214010343,\n",
              "  0.0002126987965311855,\n",
              "  0.00021187419770285487,\n",
              "  0.00020927567675244063,\n",
              "  0.0002071855269605294,\n",
              "  0.00020363413204904646,\n",
              "  0.00020155429956503212,\n",
              "  0.00020090624457225204,\n",
              "  0.00019801729649771005,\n",
              "  0.00019591700402088463,\n",
              "  0.00019325627363286912,\n",
              "  0.00019151069864165038,\n",
              "  0.0001894458255264908,\n",
              "  0.0001882730284705758,\n",
              "  0.00018590016406960785,\n",
              "  0.00018371472833678126,\n",
              "  0.00018216246098745614,\n",
              "  0.00018046032346319407,\n",
              "  0.00017813360318541527,\n",
              "  0.00017655579722486436,\n",
              "  0.00017538093379698694,\n",
              "  0.00017416357877664268,\n",
              "  0.00017171786748804152,\n",
              "  0.00016980516375042498,\n",
              "  0.00016941076319199055,\n",
              "  0.0001678474945947528,\n",
              "  0.00016554883040953428,\n",
              "  0.00016401820175815374,\n",
              "  0.0001628647733014077,\n",
              "  0.00016127413255162537,\n",
              "  0.00015980195894371718,\n",
              "  0.00015855739184189588,\n",
              "  0.0001567709696246311,\n",
              "  0.00015567950322292745,\n",
              "  0.00015434813394676894,\n",
              "  0.00015295101911760867,\n",
              "  0.00015184203220997006,\n",
              "  0.00015019070997368544,\n",
              "  0.00014914806524757296,\n",
              "  0.00014782670768909156],\n",
              " 'accuracy': [0.28125,\n",
              "  0.706250011920929,\n",
              "  0.8387500047683716,\n",
              "  0.8974999785423279,\n",
              "  0.9262499809265137,\n",
              "  0.925000011920929,\n",
              "  0.9487500190734863,\n",
              "  0.9549999833106995,\n",
              "  0.9700000286102295,\n",
              "  0.9750000238418579,\n",
              "  0.9837499856948853,\n",
              "  0.9825000166893005,\n",
              "  0.9900000095367432,\n",
              "  0.9950000047683716,\n",
              "  0.9975000023841858,\n",
              "  0.9975000023841858,\n",
              "  0.9950000047683716,\n",
              "  0.9950000047683716,\n",
              "  0.9987499713897705,\n",
              "  0.9987499713897705,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0],\n",
              " 'val_loss': [1.7811907529830933,\n",
              "  0.7918034195899963,\n",
              "  0.48534220457077026,\n",
              "  0.36739566922187805,\n",
              "  0.4285282790660858,\n",
              "  0.37597012519836426,\n",
              "  0.35495051741600037,\n",
              "  0.35289323329925537,\n",
              "  0.30900952219963074,\n",
              "  0.36889663338661194,\n",
              "  0.37952449917793274,\n",
              "  0.33635929226875305,\n",
              "  0.3403480648994446,\n",
              "  0.39732447266578674,\n",
              "  0.3388828933238983,\n",
              "  0.38661903142929077,\n",
              "  0.31610801815986633,\n",
              "  0.38234537839889526,\n",
              "  0.350153386592865,\n",
              "  0.3836006224155426,\n",
              "  0.34243687987327576,\n",
              "  0.3650430738925934,\n",
              "  0.3645305633544922,\n",
              "  0.37937209010124207,\n",
              "  0.3745129704475403,\n",
              "  0.38048964738845825,\n",
              "  0.3868251144886017,\n",
              "  0.38435474038124084,\n",
              "  0.3915272057056427,\n",
              "  0.39074936509132385,\n",
              "  0.3947603106498718,\n",
              "  0.4005376398563385,\n",
              "  0.39776161313056946,\n",
              "  0.4023522138595581,\n",
              "  0.4049374759197235,\n",
              "  0.40526917576789856,\n",
              "  0.4105636477470398,\n",
              "  0.4117756187915802,\n",
              "  0.41545572876930237,\n",
              "  0.4122108221054077,\n",
              "  0.4169963002204895,\n",
              "  0.4178752899169922,\n",
              "  0.421008825302124,\n",
              "  0.42199310660362244,\n",
              "  0.42270511388778687,\n",
              "  0.4252597391605377,\n",
              "  0.4271426498889923,\n",
              "  0.42742183804512024,\n",
              "  0.42801016569137573,\n",
              "  0.4313294589519501,\n",
              "  0.43168747425079346,\n",
              "  0.4323691427707672,\n",
              "  0.4335092604160309,\n",
              "  0.4368245601654053,\n",
              "  0.43568935990333557,\n",
              "  0.43933457136154175,\n",
              "  0.43987858295440674,\n",
              "  0.4402768611907959,\n",
              "  0.4442145526409149,\n",
              "  0.4424426257610321,\n",
              "  0.44617122411727905,\n",
              "  0.4463096857070923,\n",
              "  0.444937527179718,\n",
              "  0.44807755947113037,\n",
              "  0.4488278329372406,\n",
              "  0.44903239607810974,\n",
              "  0.4495875835418701,\n",
              "  0.4517197906970978,\n",
              "  0.45213794708251953,\n",
              "  0.4531770348548889,\n",
              "  0.45376378297805786,\n",
              "  0.4553307592868805,\n",
              "  0.4563412368297577,\n",
              "  0.45868340134620667,\n",
              "  0.4560006260871887,\n",
              "  0.45793652534484863,\n",
              "  0.4595421254634857,\n",
              "  0.4611009657382965,\n",
              "  0.46044644713401794,\n",
              "  0.46202999353408813,\n",
              "  0.4623527526855469,\n",
              "  0.46325069665908813,\n",
              "  0.46528729796409607,\n",
              "  0.4646802544593811,\n",
              "  0.465789258480072,\n",
              "  0.4666441082954407,\n",
              "  0.4677370488643646,\n",
              "  0.4674055576324463,\n",
              "  0.46861588954925537,\n",
              "  0.46923893690109253,\n",
              "  0.4704523980617523,\n",
              "  0.47081923484802246,\n",
              "  0.4716682434082031,\n",
              "  0.47216853499412537,\n",
              "  0.4729585349559784,\n",
              "  0.47458264231681824,\n",
              "  0.4736807644367218,\n",
              "  0.4755209982395172,\n",
              "  0.4755745232105255,\n",
              "  0.477016419172287,\n",
              "  0.4764311611652374,\n",
              "  0.477512925863266,\n",
              "  0.47856825590133667,\n",
              "  0.47938716411590576,\n",
              "  0.4797459840774536,\n",
              "  0.48160430788993835,\n",
              "  0.48126959800720215,\n",
              "  0.4811805486679077,\n",
              "  0.48139050602912903,\n",
              "  0.4835595190525055,\n",
              "  0.4829005300998688,\n",
              "  0.48394492268562317,\n",
              "  0.48410362005233765,\n",
              "  0.48482611775398254,\n",
              "  0.48548901081085205,\n",
              "  0.4859819710254669,\n",
              "  0.48661407828330994,\n",
              "  0.4871046543121338,\n",
              "  0.4879281520843506,\n",
              "  0.48808082938194275,\n",
              "  0.48864367604255676,\n",
              "  0.4895115792751312,\n",
              "  0.4883996546268463,\n",
              "  0.49043747782707214,\n",
              "  0.49171242117881775,\n",
              "  0.49106281995773315,\n",
              "  0.4909668266773224,\n",
              "  0.4914317727088928,\n",
              "  0.4923938810825348,\n",
              "  0.4926263689994812,\n",
              "  0.4935991168022156,\n",
              "  0.4940025210380554,\n",
              "  0.4949627220630646,\n",
              "  0.4941087067127228,\n",
              "  0.4953439235687256,\n",
              "  0.4952782094478607,\n",
              "  0.4961716830730438,\n",
              "  0.49635788798332214,\n",
              "  0.496740460395813,\n",
              "  0.4972011148929596,\n",
              "  0.4986407160758972,\n",
              "  0.4986859858036041,\n",
              "  0.49914395809173584,\n",
              "  0.49939289689064026,\n",
              "  0.5001031160354614,\n",
              "  0.4995526373386383,\n",
              "  0.5002309679985046,\n",
              "  0.5016928315162659,\n",
              "  0.5010797381401062,\n",
              "  0.5022115111351013],\n",
              " 'val_accuracy': [0.4749999940395355,\n",
              "  0.7450000047683716,\n",
              "  0.8550000190734863,\n",
              "  0.8849999904632568,\n",
              "  0.8700000047683716,\n",
              "  0.8949999809265137,\n",
              "  0.8949999809265137,\n",
              "  0.8999999761581421,\n",
              "  0.9100000262260437,\n",
              "  0.9100000262260437,\n",
              "  0.8899999856948853,\n",
              "  0.9150000214576721,\n",
              "  0.925000011920929,\n",
              "  0.9049999713897705,\n",
              "  0.9150000214576721,\n",
              "  0.9150000214576721,\n",
              "  0.9150000214576721,\n",
              "  0.9300000071525574,\n",
              "  0.925000011920929,\n",
              "  0.9200000166893005,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.925000011920929,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.9200000166893005,\n",
              "  0.9200000166893005,\n",
              "  0.925000011920929,\n",
              "  0.9200000166893005,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929,\n",
              "  0.925000011920929]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPoqQh5ZIOxH"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKR57ribIOxI",
        "outputId": "ba35adea-0b11-4d12-b606-a72c2a4aad57"
      },
      "source": [
        "#model set up\n",
        "perf=[]\n",
        "learning_rates=[0.01,0.02,0.03,0.04]\n",
        "for lr in learning_rates:\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
        "    history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "    perf.append(history.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 35ms/step - loss: 1.5045e-04 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.4095e-04 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9250\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2858e-04 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.9250\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.5236e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9250\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.4377e-04 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.3129e-04 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9250\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.4077e-04 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.9250\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.5359e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3071e-04 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9250\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.2421e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9250\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.2516e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.3628e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9250\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3632e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.3886e-04 - accuracy: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.9250\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3952e-04 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2541e-04 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9250\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3856e-04 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.0869e-04 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3690e-04 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2237e-04 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9250\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3192e-04 - accuracy: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.9250\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2489e-04 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3232e-04 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1748e-04 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.9250\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1732e-04 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.9250\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3178e-04 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2755e-04 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9250\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2332e-04 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.9250\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.3212e-04 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9250\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1297e-04 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3393e-04 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.2489e-04 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.9250\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.1199e-04 - accuracy: 1.0000 - val_loss: 0.5142 - val_accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1362e-04 - accuracy: 1.0000 - val_loss: 0.5145 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.1947e-04 - accuracy: 1.0000 - val_loss: 0.5151 - val_accuracy: 0.9250\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0493e-04 - accuracy: 1.0000 - val_loss: 0.5147 - val_accuracy: 0.9250\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.1970e-04 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.9250\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.2150e-04 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.9250\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3319e-04 - accuracy: 1.0000 - val_loss: 0.5168 - val_accuracy: 0.9250\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.2004e-04 - accuracy: 1.0000 - val_loss: 0.5165 - val_accuracy: 0.9250\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.1286e-04 - accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.9250\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.1501e-04 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.9250\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.0822e-04 - accuracy: 1.0000 - val_loss: 0.5178 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.5225e-05 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.5869e-05 - accuracy: 1.0000 - val_loss: 0.5182 - val_accuracy: 0.9250\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.1781e-04 - accuracy: 1.0000 - val_loss: 0.5184 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.6580e-05 - accuracy: 1.0000 - val_loss: 0.5188 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.9879e-05 - accuracy: 1.0000 - val_loss: 0.5192 - val_accuracy: 0.9250\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 1.0643e-04 - accuracy: 1.0000 - val_loss: 0.5189 - val_accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.9862e-05 - accuracy: 1.0000 - val_loss: 0.5197 - val_accuracy: 0.9250\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 35ms/step - loss: 1.0559e-04 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.9241e-05 - accuracy: 1.0000 - val_loss: 0.5204 - val_accuracy: 0.9250\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.0936e-05 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.9250\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0742e-04 - accuracy: 1.0000 - val_loss: 0.5206 - val_accuracy: 0.9250\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0174e-04 - accuracy: 1.0000 - val_loss: 0.5218 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.3133e-05 - accuracy: 1.0000 - val_loss: 0.5210 - val_accuracy: 0.9250\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.9861e-05 - accuracy: 1.0000 - val_loss: 0.5221 - val_accuracy: 0.9250\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0980e-04 - accuracy: 1.0000 - val_loss: 0.5227 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.3276e-05 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9250\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.8870e-05 - accuracy: 1.0000 - val_loss: 0.5223 - val_accuracy: 0.9250\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.9311e-05 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.7979e-05 - accuracy: 1.0000 - val_loss: 0.5233 - val_accuracy: 0.9250\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.8024e-05 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.0001e-04 - accuracy: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.9250\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.0075e-04 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.0793e-05 - accuracy: 1.0000 - val_loss: 0.5244 - val_accuracy: 0.9250\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.0015e-04 - accuracy: 1.0000 - val_loss: 0.5251 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.8789e-05 - accuracy: 1.0000 - val_loss: 0.5248 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.9093e-05 - accuracy: 1.0000 - val_loss: 0.5258 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.9097e-05 - accuracy: 1.0000 - val_loss: 0.5259 - val_accuracy: 0.9250\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.6067e-05 - accuracy: 1.0000 - val_loss: 0.5260 - val_accuracy: 0.9250\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.1009e-05 - accuracy: 1.0000 - val_loss: 0.5267 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.7118e-05 - accuracy: 1.0000 - val_loss: 0.5262 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.6127e-05 - accuracy: 1.0000 - val_loss: 0.5264 - val_accuracy: 0.9250\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.5924e-05 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9250\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.6665e-05 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.3816e-05 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.9250\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.0806e-05 - accuracy: 1.0000 - val_loss: 0.5279 - val_accuracy: 0.9250\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.7473e-05 - accuracy: 1.0000 - val_loss: 0.5285 - val_accuracy: 0.9250\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.3581e-05 - accuracy: 1.0000 - val_loss: 0.5285 - val_accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.9194e-05 - accuracy: 1.0000 - val_loss: 0.5284 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.2528e-05 - accuracy: 1.0000 - val_loss: 0.5292 - val_accuracy: 0.9250\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.3053e-05 - accuracy: 1.0000 - val_loss: 0.5293 - val_accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.4813e-05 - accuracy: 1.0000 - val_loss: 0.5294 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.9182e-05 - accuracy: 1.0000 - val_loss: 0.5299 - val_accuracy: 0.9250\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.8672e-05 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.9250\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.9567e-05 - accuracy: 1.0000 - val_loss: 0.5302 - val_accuracy: 0.9250\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.1025e-05 - accuracy: 1.0000 - val_loss: 0.5301 - val_accuracy: 0.9250\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.9853e-05 - accuracy: 1.0000 - val_loss: 0.5311 - val_accuracy: 0.9250\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.0407e-05 - accuracy: 1.0000 - val_loss: 0.5310 - val_accuracy: 0.9250\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.4858e-05 - accuracy: 1.0000 - val_loss: 0.5313 - val_accuracy: 0.9250\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.6559e-05 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.9250\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.1746e-05 - accuracy: 1.0000 - val_loss: 0.5319 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.2082e-05 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.2509e-05 - accuracy: 1.0000 - val_loss: 0.5323 - val_accuracy: 0.9250\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.9124e-05 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.3316e-05 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.8332e-05 - accuracy: 1.0000 - val_loss: 0.5330 - val_accuracy: 0.9250\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.0998e-05 - accuracy: 1.0000 - val_loss: 0.5328 - val_accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.6153e-05 - accuracy: 1.0000 - val_loss: 0.5335 - val_accuracy: 0.9250\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 42ms/step - loss: 8.0458e-05 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.5835e-05 - accuracy: 1.0000 - val_loss: 0.5340 - val_accuracy: 0.9250\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.9613e-05 - accuracy: 1.0000 - val_loss: 0.5346 - val_accuracy: 0.9250\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.2104e-05 - accuracy: 1.0000 - val_loss: 0.5341 - val_accuracy: 0.9250\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.7930e-05 - accuracy: 1.0000 - val_loss: 0.5351 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.1451e-05 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9250\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.6588e-05 - accuracy: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.9250\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.4582e-05 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.1845e-05 - accuracy: 1.0000 - val_loss: 0.5355 - val_accuracy: 0.9250\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.8532e-05 - accuracy: 1.0000 - val_loss: 0.5354 - val_accuracy: 0.9250\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.8753e-05 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.5771e-05 - accuracy: 1.0000 - val_loss: 0.5362 - val_accuracy: 0.9250\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.5808e-05 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.7411e-05 - accuracy: 1.0000 - val_loss: 0.5365 - val_accuracy: 0.9250\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.8119e-05 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.0479e-05 - accuracy: 1.0000 - val_loss: 0.5371 - val_accuracy: 0.9250\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.7726e-05 - accuracy: 1.0000 - val_loss: 0.5377 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.1252e-05 - accuracy: 1.0000 - val_loss: 0.5375 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.6939e-05 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.9428e-05 - accuracy: 1.0000 - val_loss: 0.5383 - val_accuracy: 0.9250\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.4855e-05 - accuracy: 1.0000 - val_loss: 0.5383 - val_accuracy: 0.9250\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.0986e-05 - accuracy: 1.0000 - val_loss: 0.5388 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 7.6045e-05 - accuracy: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.7406e-05 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.9250\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.7195e-05 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.9250\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.5669e-05 - accuracy: 1.0000 - val_loss: 0.5395 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.3561e-05 - accuracy: 1.0000 - val_loss: 0.5394 - val_accuracy: 0.9250\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.1284e-05 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.9250\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.6614e-05 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.9250\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.5854e-05 - accuracy: 1.0000 - val_loss: 0.5403 - val_accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.8118e-05 - accuracy: 1.0000 - val_loss: 0.5402 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.2860e-05 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.9250\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.5504e-05 - accuracy: 1.0000 - val_loss: 0.5409 - val_accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.7171e-05 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.0595e-05 - accuracy: 1.0000 - val_loss: 0.5415 - val_accuracy: 0.9250\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.2501e-05 - accuracy: 1.0000 - val_loss: 0.5412 - val_accuracy: 0.9250\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.1014e-05 - accuracy: 1.0000 - val_loss: 0.5417 - val_accuracy: 0.9250\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.2221e-05 - accuracy: 1.0000 - val_loss: 0.5416 - val_accuracy: 0.9250\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.9223e-05 - accuracy: 1.0000 - val_loss: 0.5424 - val_accuracy: 0.9250\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.1983e-05 - accuracy: 1.0000 - val_loss: 0.5423 - val_accuracy: 0.9250\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.7508e-05 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.9250\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.8908e-05 - accuracy: 1.0000 - val_loss: 0.5430 - val_accuracy: 0.9250\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.5212e-05 - accuracy: 1.0000 - val_loss: 0.5431 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.7613e-05 - accuracy: 1.0000 - val_loss: 0.5435 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.7892e-05 - accuracy: 1.0000 - val_loss: 0.5434 - val_accuracy: 0.9250\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.1181e-05 - accuracy: 1.0000 - val_loss: 0.5436 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.8702e-05 - accuracy: 1.0000 - val_loss: 0.5439 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.4751e-05 - accuracy: 1.0000 - val_loss: 0.5440 - val_accuracy: 0.9250\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.4944e-05 - accuracy: 1.0000 - val_loss: 0.5438 - val_accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.1175e-05 - accuracy: 1.0000 - val_loss: 0.5444 - val_accuracy: 0.9250\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 35ms/step - loss: 6.4533e-05 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.0983e-05 - accuracy: 1.0000 - val_loss: 0.5448 - val_accuracy: 0.9250\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.6013e-05 - accuracy: 1.0000 - val_loss: 0.5453 - val_accuracy: 0.9250\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6000e-05 - accuracy: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.9250\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.2733e-05 - accuracy: 1.0000 - val_loss: 0.5457 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5.7616e-05 - accuracy: 1.0000 - val_loss: 0.5451 - val_accuracy: 0.9250\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.1742e-05 - accuracy: 1.0000 - val_loss: 0.5458 - val_accuracy: 0.9250\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.8383e-05 - accuracy: 1.0000 - val_loss: 0.5462 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 5.8079e-05 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 0.9250\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 5.5391e-05 - accuracy: 1.0000 - val_loss: 0.5460 - val_accuracy: 0.9250\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.5535e-05 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.1390e-05 - accuracy: 1.0000 - val_loss: 0.5466 - val_accuracy: 0.9250\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.1435e-05 - accuracy: 1.0000 - val_loss: 0.5469 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.2754e-05 - accuracy: 1.0000 - val_loss: 0.5468 - val_accuracy: 0.9250\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.3402e-05 - accuracy: 1.0000 - val_loss: 0.5477 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.7236e-05 - accuracy: 1.0000 - val_loss: 0.5474 - val_accuracy: 0.9250\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.3123e-05 - accuracy: 1.0000 - val_loss: 0.5478 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.9809e-05 - accuracy: 1.0000 - val_loss: 0.5476 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.2463e-05 - accuracy: 1.0000 - val_loss: 0.5482 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.6544e-05 - accuracy: 1.0000 - val_loss: 0.5483 - val_accuracy: 0.9250\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.0946e-05 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9250\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.7869e-05 - accuracy: 1.0000 - val_loss: 0.5488 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.2148e-05 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.5070e-05 - accuracy: 1.0000 - val_loss: 0.5486 - val_accuracy: 0.9250\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 5.4834e-05 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.9250\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.1807e-05 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.0166e-05 - accuracy: 1.0000 - val_loss: 0.5493 - val_accuracy: 0.9250\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.8331e-05 - accuracy: 1.0000 - val_loss: 0.5496 - val_accuracy: 0.9250\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.2749e-05 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.9250\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 5.4007e-05 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.4052e-05 - accuracy: 1.0000 - val_loss: 0.5500 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.9714e-05 - accuracy: 1.0000 - val_loss: 0.5505 - val_accuracy: 0.9250\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.3758e-05 - accuracy: 1.0000 - val_loss: 0.5506 - val_accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5.5323e-05 - accuracy: 1.0000 - val_loss: 0.5507 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.8123e-05 - accuracy: 1.0000 - val_loss: 0.5510 - val_accuracy: 0.9250\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5.1583e-05 - accuracy: 1.0000 - val_loss: 0.5508 - val_accuracy: 0.9250\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.8531e-05 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.9250\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.9582e-05 - accuracy: 1.0000 - val_loss: 0.5511 - val_accuracy: 0.9250\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.5305e-05 - accuracy: 1.0000 - val_loss: 0.5519 - val_accuracy: 0.9250\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.9506e-05 - accuracy: 1.0000 - val_loss: 0.5517 - val_accuracy: 0.9250\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 5.5779e-05 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9250\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.6916e-05 - accuracy: 1.0000 - val_loss: 0.5523 - val_accuracy: 0.9250\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.3998e-05 - accuracy: 1.0000 - val_loss: 0.5524 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.7767e-05 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.7953e-05 - accuracy: 1.0000 - val_loss: 0.5527 - val_accuracy: 0.9250\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.8947e-05 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.8747e-05 - accuracy: 1.0000 - val_loss: 0.5531 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.5460e-05 - accuracy: 1.0000 - val_loss: 0.5532 - val_accuracy: 0.9250\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.3924e-05 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.0900e-05 - accuracy: 1.0000 - val_loss: 0.5535 - val_accuracy: 0.9250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-ZpwjTLIOxJ"
      },
      "source": [
        "#accuracy is 92.5% for each learning rate for sgd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8w8QvzlIOxK",
        "outputId": "a671abe8-c20d-4d54-efb2-7a0e5c336a18"
      },
      "source": [
        "history.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929,\n",
              " 0.925000011920929]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4at8iXPsIOxL",
        "outputId": "a9443af8-8747-4dad-ef4c-f04d057788c5"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euXPR9fwIOxM",
        "outputId": "2b0f04ec-d2b4-418d-b142-51b5668aab38"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwxi_bTDIOxM",
        "outputId": "8348b578-cde3-4485-e92d-672d8ba0b0f1"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y0UAxL4IOxO"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qjGLPKqIOxP",
        "outputId": "54efbf32-6574-4e22-ee63-81f2bc4f8ff4"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adagrad = Adagrad(lr=0.01,initial_accumulator_value=0.1,\n",
        "    epsilon=1e-07, name=\"Adagrad\")\n",
        "\n",
        "# Compile the model\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adagrad)\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=150)\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 2.2873\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 2.2020\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.9699\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.3609\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.8147\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.7210\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4995\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.5483\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4282\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.3568: 0s - loss: \n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3214\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3462\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.3082\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2916\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2466\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1979\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2180\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.2031\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1683\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.2086\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.1909: 0s - loss:\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1444\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.1488\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1104\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1179\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1027\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1093\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1012\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0957\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0911\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.1120\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0735\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0716\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0597\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0566\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0503\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0600\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0451\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0504\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0471\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0434\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0376\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0396\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0312\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0279\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0313\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.0250\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0213: 0s - loss: 0\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0244\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0206\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0201: 0s - loss: \n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0170\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0175\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0162\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0201\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0155\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0147\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0164\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0154\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0145\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0133\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0127\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0138\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0112\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0107\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0101\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0088\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0098\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0091\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0095\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0088\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0109\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0098\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0080\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0077\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0071\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0076\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0066\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0077\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0071\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0061\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0074\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0063\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0071\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0077\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0061\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0055\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0056\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0058\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0053\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0053\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0059\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0049\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0047\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0053\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0043\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0048\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0046\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0045\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0040\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0043\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0051\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0045\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0048\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0044\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0035\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0043\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0042\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0039\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0037\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0040\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0035\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0033\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0035\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0031\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0038\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0032\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0036\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0029\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0031\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0032\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0030\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0033\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0034\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0027\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0031\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0026\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0028\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0030\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0026\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0026\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0030\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0025\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0029\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0026\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0026: 0s - los\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0024\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0024\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0025\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0023\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0028\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0023\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0023\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0025\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0023\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0022\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0025\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0022\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0021\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - ETA: 0s - loss: 0.002 - 1s 21ms/step - loss: 0.0022\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.3913\n",
            "Accuracy: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQDZU7ABIOxQ"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UiDW7ykIOxQ",
        "outputId": "53a820ab-1f83-4a30-c92d-269ace8ef122"
      },
      "source": [
        "#model set up\n",
        "perf=[]\n",
        "learning_rates=[0.01,0.02,0.03,0.04]\n",
        "for lr in learning_rates:\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adagrad,metrics=['accuracy'])\n",
        "    history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "    perf.append(history.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 37ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9300\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9300\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9300\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.9300\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9300\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9300\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9300\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9300\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9300\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9300\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9300\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9300\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9300\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9300\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9300\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9300\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9300\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9300\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9300\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9300\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9300\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9300\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9300\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 37ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9300\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9300\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.9300\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9300\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9300\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9300\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9300\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9300\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9300\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9300\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9300\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9300\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9300\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 36ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9300\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9250\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9300\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9300\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9300\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9300\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9250\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9300\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9300\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9300\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9300\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9250\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9300\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9300\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9300\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9300\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9300\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9300\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9300\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9300\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9300\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9300\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9300\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9300\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9300\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9300\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9300\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9300\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9300\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.5429e-04 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9300\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.5908e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.5762e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9300\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9300\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.8251e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9300\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 37ms/step - loss: 9.5597e-04 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.1628e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9250\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.7555e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9250\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.9408e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9300\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.6768e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.6591e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9300\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9250\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.3771e-04 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9250\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.6059e-04 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9250\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.6486e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 9.5606e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9250\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 9.9048e-04 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9300\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.4687e-04 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9300\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.7083e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.6282e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9250\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.5612e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.5754e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.0855e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.5443e-04 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9300\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.2315e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9300\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.4321e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.9435e-04 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.2910e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9250\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.2742e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9250\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.5144e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.6568e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9300\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.6664e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9300\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.2083e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9250\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.5150e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.7082e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.3516e-04 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9250\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.8444e-04 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.7038e-04 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 8.2541e-04 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9250\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.9537e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9300\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.9230e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9250\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.3943e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9250\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.9373e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9250\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.8277e-04 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.9300\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.4191e-04 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9300\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.9297e-04 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.9250\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.9556e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.2498e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 7.7262e-04 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9250\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.5459e-04 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.2970e-04 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 6.5416e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9250\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.8797e-04 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.5134e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9250\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 42ms/step - loss: 7.3244e-04 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9250\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 7.0199e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9250\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 6.7176e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9250\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 7.6314e-04 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.9250\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 7.4573e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9250\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 6.6756e-04 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9250\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 7.8113e-04 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9250\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 8.1764e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9250\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 7.2343e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9250\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 6.6670e-04 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.9250\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.6988e-04 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.4048e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9250\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.6878e-04 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9250\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.3628e-04 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9300\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.5442e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.7103e-04 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9250\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.4337e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9250\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.9037e-04 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9250\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.0729e-04 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9250\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6884e-04 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9250\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.2083e-04 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9250\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.5909e-04 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.7787e-04 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9250\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.5160e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9250\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.4903e-04 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9250\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6908e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9250\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.7997e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9250\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.8037e-04 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9250\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.2442e-04 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9250\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.7120e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9250\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.6465e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9250\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.5891e-04 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9250\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.2021e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9250\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.8888e-04 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9250\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.5456e-04 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9250\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.3060e-04 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9250\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.0652e-04 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9250\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6651e-04 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9250\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.0950e-04 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.9250\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.0073e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9250\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.6833e-04 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9250\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.3107e-04 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9250\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.3428e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9250\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.7862e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9250\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.1757e-04 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9250\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.8342e-04 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9250\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.8326e-04 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9250\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.2322e-04 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9250\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.3080e-04 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9250\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.0248e-04 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r39q82VpIOxR"
      },
      "source": [
        "#accuracy is slightly different for each learning rate in adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKrwMABtIOxS",
        "outputId": "abcf975b-2a87-4ab3-9a56-7090fdf3a68f"
      },
      "source": [
        "tf.keras.optimizers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'tensorflow.keras.optimizers' from 'C:\\\\Users\\\\awmna\\\\anaconda3\\\\envs\\\\myenv\\\\lib\\\\site-packages\\\\tensorflow\\\\keras\\\\optimizers\\\\__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfmPap5RIOxT"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUyFhn_5IOxU",
        "outputId": "af26a7cc-f314-4d34-b5af-7414f176551c"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adam=Adam(\n",
        "    learning_rate=0.001,\n",
        "    beta_1=0.9,\n",
        "    beta_2=0.999,\n",
        "    epsilon=1e-07,\n",
        "    amsgrad=False,\n",
        "    name=\"Adam\")\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam)\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=150)\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 2.1429\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.0039\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.4662\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.3557\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2932\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1780\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1593\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1365\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.1074\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0636\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0536\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0624\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0460\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0346\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0231\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0266\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0168\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0092\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0093\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0086\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0077\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0056\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0048\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0032\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0032\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0030\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0026\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0024\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0023\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0017\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0019\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0018\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0014\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0014\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0013\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0011\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0012\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0011\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0012\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0011\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 9.1402e-04\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 9.0556e-04: 0s - loss: 8.\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 8.0422e-04\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.8546e-04\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7.1444e-04\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 7.7675e-04\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.3588e-04\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.0878e-04\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.4515e-04\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.6132e-04\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.0538e-04\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.4567e-04\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.4099e-04\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.6043e-04: 0s - loss: 4.5341e\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.3672e-04\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 4.4716e-04\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 3.8789e-04\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.5463e-04\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.2241e-04\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 3.9039e-04\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 3.5543e-04\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.4794e-04\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.3704e-04\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.8547e-04\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.8464e-04\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.7773e-04\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.4386e-04\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.6807e-04\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.4596e-04\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 2.5202e-04\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.2587e-04\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.8177e-04\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 2.5699e-04\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 2.0481e-04\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.9739e-04\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.8784e-04\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.1292e-04\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.8045e-04\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.9550e-04\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.9125e-04\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.5662e-04\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.7513e-04\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.8125e-04\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.9232e-04\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.9393e-04\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.5206e-04\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.4450e-04\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.4370e-04\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.4740e-04\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.3706e-04\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2835e-04\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.4321e-04\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3436e-04\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.1918e-04\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3094e-04\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.8740e-05\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.1762e-04\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1045e-04\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.0047e-04\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 9.1415e-05: 0s - loss: 8.7325e-\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.5760e-05\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.2003e-04\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.0344e-04\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.1041e-04\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.0245e-04\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7.9028e-05\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 9.3492e-05\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.0034e-04\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 8.6729e-05\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 8.2149e-05\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 8.8665e-05\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7.7290e-05\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7.9418e-05\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7.3418e-05\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 7.3618e-05\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 8.5893e-05\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.6783e-05\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 7.8863e-05\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.2386e-05\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.6739e-05\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 6.3977e-05\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.7454e-05\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 6.7099e-05\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 7.2154e-05\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 5.6077e-05\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 6.1103e-05\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5.2961e-05\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5.5456e-05\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5.5837e-05\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.0084e-05\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5.0106e-05\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 5.4583e-05\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 4.7086e-05\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.4399e-05\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.9541e-05\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 4.8331e-05\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.5050e-05: 0s - loss: 4.4271\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 4.3410e-05\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.5092e-05\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 4.3316e-05\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 4.9643e-05\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 4.0502e-05\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 3.8428e-05\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.6106e-05\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 3.8832e-05\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 3.4711e-05\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.0948e-05\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.6498e-05\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 3.3991e-05\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.5803e-05\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.4699\n",
            "Accuracy: 0.935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSKvUgaVIOxV"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59M1blcrIOxV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm5sA5NUIOxW",
        "outputId": "61a70da2-ce2e-4053-a58a-914670322070"
      },
      "source": [
        "#model set up\n",
        "perf=[]\n",
        "learning_rates=[0.01,0.02,0.03,0.04]\n",
        "for lr in learning_rates:\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=['accuracy'])\n",
        "    history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "    perf.append(history.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 36ms/step - loss: 3.7458e-05 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9350\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.3202e-05 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9350\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.1561e-05 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 36ms/step - loss: 3.3796e-05 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.9975e-05 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9350\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.0328e-05 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9350\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.1753e-05 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9350\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.1700e-05 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9350\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.1777e-05 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.7682e-05 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.7722e-05 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9350\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.8462e-05 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9350\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.0386e-05 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9350\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.8495e-05 - accuracy: 1.0000 - val_loss: 0.4789 - val_accuracy: 0.9350\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.9637e-05 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9350\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.4988e-05 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.5695e-05 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.9350\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2274e-05 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.9350\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.7272e-05 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 2.3923e-05 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 2.4769e-05 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.5593e-05 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9350\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.5967e-05 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.9350\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.0749e-05 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9350\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.3294e-05 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9350\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.3172e-05 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.2194e-05 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2247e-05 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.4145e-05 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.8963e-05 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2254e-05 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9350\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.1443e-05 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9350\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.8676e-05 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9350\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.9996e-05 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.8977e-05 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.9350\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.7502e-05 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.9580e-05 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9350\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.8302e-05 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9350\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.0356e-05 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.9350\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.8878e-05 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.9350\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.7134e-05 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.7594e-05 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.9350\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.6786e-05 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.9350\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.4756e-05 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.9350\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 1.5678e-05 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.9350\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.8202e-05 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.9350\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.4841e-05 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.2536e-05 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9350\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.5417e-05 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.4647e-05 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9350\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 36ms/step - loss: 1.5253e-05 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.9350\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.3489e-05 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.9350\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.2882e-05 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3739e-05 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.2264e-05 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9350\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.2452e-05 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9350\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.3054e-05 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9350\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3091e-05 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.9350\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3089e-05 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.1473e-05 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1504e-05 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.9350\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1869e-05 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.9350\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2660e-05 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.9350\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1888e-05 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.9350\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.2380e-05 - accuracy: 1.0000 - val_loss: 0.5133 - val_accuracy: 0.9350\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0520e-05 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.0777e-05 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9350\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 9.3806e-06 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.9350\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1440e-05 - accuracy: 1.0000 - val_loss: 0.5155 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0117e-05 - accuracy: 1.0000 - val_loss: 0.5161 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0492e-05 - accuracy: 1.0000 - val_loss: 0.5154 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0821e-05 - accuracy: 1.0000 - val_loss: 0.5167 - val_accuracy: 0.9350\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1080e-05 - accuracy: 1.0000 - val_loss: 0.5172 - val_accuracy: 0.9350\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.8699e-06 - accuracy: 1.0000 - val_loss: 0.5169 - val_accuracy: 0.9350\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.9056e-06 - accuracy: 1.0000 - val_loss: 0.5194 - val_accuracy: 0.9350\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.8969e-06 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.4891e-06 - accuracy: 1.0000 - val_loss: 0.5193 - val_accuracy: 0.9350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.5184e-06 - accuracy: 1.0000 - val_loss: 0.5207 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0386e-05 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.1666e-06 - accuracy: 1.0000 - val_loss: 0.5212 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.5724e-06 - accuracy: 1.0000 - val_loss: 0.5214 - val_accuracy: 0.9350\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 9.2095e-06 - accuracy: 1.0000 - val_loss: 0.5222 - val_accuracy: 0.9350\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.0773e-06 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.9350\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.6459e-06 - accuracy: 1.0000 - val_loss: 0.5232 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.2641e-06 - accuracy: 1.0000 - val_loss: 0.5255 - val_accuracy: 0.9350\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.6130e-06 - accuracy: 1.0000 - val_loss: 0.5240 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.5154e-06 - accuracy: 1.0000 - val_loss: 0.5256 - val_accuracy: 0.9350\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.0000e-06 - accuracy: 1.0000 - val_loss: 0.5257 - val_accuracy: 0.9350\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.8820e-06 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9350\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 8.2438e-06 - accuracy: 1.0000 - val_loss: 0.5278 - val_accuracy: 0.9350\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.4774e-06 - accuracy: 1.0000 - val_loss: 0.5276 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.6785e-06 - accuracy: 1.0000 - val_loss: 0.5291 - val_accuracy: 0.9350\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 7.3824e-06 - accuracy: 1.0000 - val_loss: 0.5295 - val_accuracy: 0.9350\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.4890e-06 - accuracy: 1.0000 - val_loss: 0.5297 - val_accuracy: 0.9350\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.8824e-06 - accuracy: 1.0000 - val_loss: 0.5309 - val_accuracy: 0.9350\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.0054e-06 - accuracy: 1.0000 - val_loss: 0.5304 - val_accuracy: 0.9350\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.5634e-06 - accuracy: 1.0000 - val_loss: 0.5314 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.5507e-06 - accuracy: 1.0000 - val_loss: 0.5325 - val_accuracy: 0.9350\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.8091e-06 - accuracy: 1.0000 - val_loss: 0.5318 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.4782e-06 - accuracy: 1.0000 - val_loss: 0.5333 - val_accuracy: 0.9350\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 36ms/step - loss: 6.7602e-06 - accuracy: 1.0000 - val_loss: 0.5345 - val_accuracy: 0.9350\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.9726e-06 - accuracy: 1.0000 - val_loss: 0.5342 - val_accuracy: 0.9350\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.7287e-06 - accuracy: 1.0000 - val_loss: 0.5357 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.0883e-06 - accuracy: 1.0000 - val_loss: 0.5353 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.4538e-06 - accuracy: 1.0000 - val_loss: 0.5363 - val_accuracy: 0.9350\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.5465e-06 - accuracy: 1.0000 - val_loss: 0.5368 - val_accuracy: 0.9350\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.8268e-06 - accuracy: 1.0000 - val_loss: 0.5370 - val_accuracy: 0.9350\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.8534e-06 - accuracy: 1.0000 - val_loss: 0.5385 - val_accuracy: 0.9350\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.8368e-06 - accuracy: 1.0000 - val_loss: 0.5381 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.1398e-06 - accuracy: 1.0000 - val_loss: 0.5384 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.1486e-06 - accuracy: 1.0000 - val_loss: 0.5401 - val_accuracy: 0.9350\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.3467e-06 - accuracy: 1.0000 - val_loss: 0.5400 - val_accuracy: 0.9350\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.6824e-06 - accuracy: 1.0000 - val_loss: 0.5413 - val_accuracy: 0.9350\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 5.3393e-06 - accuracy: 1.0000 - val_loss: 0.5411 - val_accuracy: 0.9350\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 5.5680e-06 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9350\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 4.7567e-06 - accuracy: 1.0000 - val_loss: 0.5427 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 4.8577e-06 - accuracy: 1.0000 - val_loss: 0.5429 - val_accuracy: 0.9350\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.2365e-06 - accuracy: 1.0000 - val_loss: 0.5426 - val_accuracy: 0.9350\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.1464e-06 - accuracy: 1.0000 - val_loss: 0.5449 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.5760e-06 - accuracy: 1.0000 - val_loss: 0.5455 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.7535e-06 - accuracy: 1.0000 - val_loss: 0.5447 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.8837e-06 - accuracy: 1.0000 - val_loss: 0.5459 - val_accuracy: 0.9350\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.0358e-06 - accuracy: 1.0000 - val_loss: 0.5464 - val_accuracy: 0.9350\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.0365e-06 - accuracy: 1.0000 - val_loss: 0.5461 - val_accuracy: 0.9350\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.4835e-06 - accuracy: 1.0000 - val_loss: 0.5484 - val_accuracy: 0.9350\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.5060e-06 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.3154e-06 - accuracy: 1.0000 - val_loss: 0.5485 - val_accuracy: 0.9350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 4.3330e-06 - accuracy: 1.0000 - val_loss: 0.5498 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.7421e-06 - accuracy: 1.0000 - val_loss: 0.5501 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.7346e-06 - accuracy: 1.0000 - val_loss: 0.5502 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.3675e-06 - accuracy: 1.0000 - val_loss: 0.5504 - val_accuracy: 0.9350\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.1992e-06 - accuracy: 1.0000 - val_loss: 0.5512 - val_accuracy: 0.9350\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 3.7026e-06 - accuracy: 1.0000 - val_loss: 0.5529 - val_accuracy: 0.9350\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.9556e-06 - accuracy: 1.0000 - val_loss: 0.5521 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.8004e-06 - accuracy: 1.0000 - val_loss: 0.5543 - val_accuracy: 0.9350\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.4941e-06 - accuracy: 1.0000 - val_loss: 0.5530 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.9074e-06 - accuracy: 1.0000 - val_loss: 0.5545 - val_accuracy: 0.9350\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.6896e-06 - accuracy: 1.0000 - val_loss: 0.5546 - val_accuracy: 0.9350\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 4.0852e-06 - accuracy: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.9350\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.7961e-06 - accuracy: 1.0000 - val_loss: 0.5566 - val_accuracy: 0.9350\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.4386e-06 - accuracy: 1.0000 - val_loss: 0.5562 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.5342e-06 - accuracy: 1.0000 - val_loss: 0.5578 - val_accuracy: 0.9350\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.4151e-06 - accuracy: 1.0000 - val_loss: 0.5581 - val_accuracy: 0.9350\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.0006e-06 - accuracy: 1.0000 - val_loss: 0.5583 - val_accuracy: 0.9350\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.1742e-06 - accuracy: 1.0000 - val_loss: 0.5595 - val_accuracy: 0.9350\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.7003e-06 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.9350\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.0437e-06 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.5768e-06 - accuracy: 1.0000 - val_loss: 0.5610 - val_accuracy: 0.9350\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.1499e-06 - accuracy: 1.0000 - val_loss: 0.5603 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.0028e-06 - accuracy: 1.0000 - val_loss: 0.5617 - val_accuracy: 0.9350\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 35ms/step - loss: 3.1354e-06 - accuracy: 1.0000 - val_loss: 0.5629 - val_accuracy: 0.9350\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.7641e-06 - accuracy: 1.0000 - val_loss: 0.5626 - val_accuracy: 0.9350\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.6608e-06 - accuracy: 1.0000 - val_loss: 0.5640 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.8206e-06 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.5349e-06 - accuracy: 1.0000 - val_loss: 0.5645 - val_accuracy: 0.9350\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.5762e-06 - accuracy: 1.0000 - val_loss: 0.5653 - val_accuracy: 0.9350\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.7113e-06 - accuracy: 1.0000 - val_loss: 0.5654 - val_accuracy: 0.9350\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.7314e-06 - accuracy: 1.0000 - val_loss: 0.5668 - val_accuracy: 0.9350\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.7123e-06 - accuracy: 1.0000 - val_loss: 0.5664 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.3970e-06 - accuracy: 1.0000 - val_loss: 0.5666 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.4034e-06 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.9350\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.5032e-06 - accuracy: 1.0000 - val_loss: 0.5681 - val_accuracy: 0.9350\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.6512e-06 - accuracy: 1.0000 - val_loss: 0.5694 - val_accuracy: 0.9350\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.4955e-06 - accuracy: 1.0000 - val_loss: 0.5692 - val_accuracy: 0.9350\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 2.6014e-06 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 0.9350\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.2349e-06 - accuracy: 1.0000 - val_loss: 0.5707 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.2705e-06 - accuracy: 1.0000 - val_loss: 0.5708 - val_accuracy: 0.9350\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.9866e-06 - accuracy: 1.0000 - val_loss: 0.5705 - val_accuracy: 0.9350\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.4054e-06 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.1531e-06 - accuracy: 1.0000 - val_loss: 0.5733 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2305e-06 - accuracy: 1.0000 - val_loss: 0.5726 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2913e-06 - accuracy: 1.0000 - val_loss: 0.5737 - val_accuracy: 0.9350\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.3743e-06 - accuracy: 1.0000 - val_loss: 0.5742 - val_accuracy: 0.9350\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.9029e-06 - accuracy: 1.0000 - val_loss: 0.5741 - val_accuracy: 0.9350\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.1042e-06 - accuracy: 1.0000 - val_loss: 0.5761 - val_accuracy: 0.9350\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.1223e-06 - accuracy: 1.0000 - val_loss: 0.5762 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.0322e-06 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.9350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.0381e-06 - accuracy: 1.0000 - val_loss: 0.5775 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2382e-06 - accuracy: 1.0000 - val_loss: 0.5778 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.7620e-06 - accuracy: 1.0000 - val_loss: 0.5779 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.0589e-06 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.9350\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.9790e-06 - accuracy: 1.0000 - val_loss: 0.5789 - val_accuracy: 0.9350\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.7508e-06 - accuracy: 1.0000 - val_loss: 0.5805 - val_accuracy: 0.9350\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.8677e-06 - accuracy: 1.0000 - val_loss: 0.5797 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.8019e-06 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.9350\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 1.6530e-06 - accuracy: 1.0000 - val_loss: 0.5807 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.8501e-06 - accuracy: 1.0000 - val_loss: 0.5819 - val_accuracy: 0.9350\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 1.7540e-06 - accuracy: 1.0000 - val_loss: 0.5821 - val_accuracy: 0.9350\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.9387e-06 - accuracy: 1.0000 - val_loss: 0.5836 - val_accuracy: 0.9350\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.7963e-06 - accuracy: 1.0000 - val_loss: 0.5841 - val_accuracy: 0.9350\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.6302e-06 - accuracy: 1.0000 - val_loss: 0.5837 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.6710e-06 - accuracy: 1.0000 - val_loss: 0.5852 - val_accuracy: 0.9350\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.6242e-06 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.9350\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.4244e-06 - accuracy: 1.0000 - val_loss: 0.5856 - val_accuracy: 0.9350\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.5039e-06 - accuracy: 1.0000 - val_loss: 0.5869 - val_accuracy: 0.9350\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.7569e-06 - accuracy: 1.0000 - val_loss: 0.5864 - val_accuracy: 0.9350\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.4494e-06 - accuracy: 1.0000 - val_loss: 0.5873 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.2284e-06 - accuracy: 1.0000 - val_loss: 0.5882 - val_accuracy: 0.9350\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.4971e-06 - accuracy: 1.0000 - val_loss: 0.5876 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 1.4301e-06 - accuracy: 1.0000 - val_loss: 0.5890 - val_accuracy: 0.9350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0TSzE-OIOxa"
      },
      "source": [
        "#accuracy is 93.5% for each learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR75zjrkIOxa"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppSSjZVqIOxb",
        "outputId": "0f7167f9-95de-4b1d-efbd-18061c1ee663"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adamax=Adamax(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\")\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adamax)\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=150)\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.2260\n",
            "Epoch 2/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.7080\n",
            "Epoch 3/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.9766\n",
            "Epoch 4/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.5855\n",
            "Epoch 5/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.4685\n",
            "Epoch 6/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.3699\n",
            "Epoch 7/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3452\n",
            "Epoch 8/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3207\n",
            "Epoch 9/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.2597\n",
            "Epoch 10/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.2131\n",
            "Epoch 11/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1954: 0s - loss\n",
            "Epoch 12/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.2220\n",
            "Epoch 13/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1843\n",
            "Epoch 14/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1606\n",
            "Epoch 15/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1465\n",
            "Epoch 16/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1336\n",
            "Epoch 17/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1332\n",
            "Epoch 18/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1117\n",
            "Epoch 19/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1015\n",
            "Epoch 20/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1268\n",
            "Epoch 21/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1006\n",
            "Epoch 22/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0697\n",
            "Epoch 23/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0893\n",
            "Epoch 24/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0627\n",
            "Epoch 25/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0660\n",
            "Epoch 26/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0703\n",
            "Epoch 27/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0446\n",
            "Epoch 28/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0537\n",
            "Epoch 29/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0464\n",
            "Epoch 30/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0346\n",
            "Epoch 31/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0424\n",
            "Epoch 32/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0329\n",
            "Epoch 33/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0266\n",
            "Epoch 34/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0250\n",
            "Epoch 35/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0203\n",
            "Epoch 36/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0179: 0s - lo\n",
            "Epoch 37/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0172\n",
            "Epoch 38/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0137\n",
            "Epoch 39/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0155\n",
            "Epoch 40/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0149\n",
            "Epoch 41/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0110\n",
            "Epoch 42/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0122\n",
            "Epoch 43/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0109\n",
            "Epoch 44/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0077\n",
            "Epoch 45/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0070\n",
            "Epoch 46/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0077\n",
            "Epoch 47/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0070\n",
            "Epoch 48/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0050\n",
            "Epoch 49/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0066\n",
            "Epoch 50/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0058\n",
            "Epoch 51/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0048\n",
            "Epoch 52/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0042\n",
            "Epoch 53/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0040\n",
            "Epoch 54/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0039\n",
            "Epoch 55/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0046\n",
            "Epoch 56/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0037\n",
            "Epoch 57/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0031\n",
            "Epoch 58/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0035\n",
            "Epoch 59/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0034\n",
            "Epoch 60/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0032\n",
            "Epoch 61/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0027\n",
            "Epoch 62/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0025\n",
            "Epoch 63/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0028: 0s - loss: 0.00\n",
            "Epoch 64/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0022\n",
            "Epoch 65/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.0022\n",
            "Epoch 66/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0021\n",
            "Epoch 67/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0018\n",
            "Epoch 68/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0019\n",
            "Epoch 69/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0017\n",
            "Epoch 70/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0017\n",
            "Epoch 71/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0016\n",
            "Epoch 72/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0018\n",
            "Epoch 73/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0016\n",
            "Epoch 74/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0014\n",
            "Epoch 75/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0013\n",
            "Epoch 76/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0012ETA: 0s - loss: 0.0\n",
            "Epoch 77/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0012\n",
            "Epoch 78/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0010\n",
            "Epoch 79/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0012\n",
            "Epoch 80/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0011\n",
            "Epoch 81/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.0106e-04\n",
            "Epoch 82/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0011\n",
            "Epoch 83/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0010\n",
            "Epoch 84/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0011\n",
            "Epoch 85/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0010\n",
            "Epoch 86/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 8.5761e-04\n",
            "Epoch 87/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 7.9269e-04\n",
            "Epoch 88/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 7.6228e-04\n",
            "Epoch 89/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.6193e-04\n",
            "Epoch 90/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.8037e-04\n",
            "Epoch 91/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.7098e-04\n",
            "Epoch 92/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.4810e-04\n",
            "Epoch 93/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.5222e-04: 0s - loss: 6.5081e-\n",
            "Epoch 94/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.9620e-04\n",
            "Epoch 95/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.6584e-04\n",
            "Epoch 96/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.6204e-04\n",
            "Epoch 97/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5.4262e-04\n",
            "Epoch 98/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 5.2445e-04\n",
            "Epoch 99/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 4.6965e-04\n",
            "Epoch 100/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.5307e-04: 0s - loss: 4.1450\n",
            "Epoch 101/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.3265e-04\n",
            "Epoch 102/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 5.4743e-04\n",
            "Epoch 103/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.4554e-04\n",
            "Epoch 104/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.1735e-04\n",
            "Epoch 105/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.5466e-04\n",
            "Epoch 106/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.3738e-04\n",
            "Epoch 107/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.0112e-04\n",
            "Epoch 108/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 4.0324e-04\n",
            "Epoch 109/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.6169e-04\n",
            "Epoch 110/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.4411e-04\n",
            "Epoch 111/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.2757e-04\n",
            "Epoch 112/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.9747e-04\n",
            "Epoch 113/150\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.9205e-04: 0s - loss: 2.8964e-\n",
            "Epoch 114/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.8793e-04\n",
            "Epoch 115/150\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.7365e-04: 0s - loss: 2.5\n",
            "Epoch 116/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.2259e-04\n",
            "Epoch 117/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.4799e-04\n",
            "Epoch 118/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.8373e-04\n",
            "Epoch 119/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2077e-04\n",
            "Epoch 120/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2380e-04\n",
            "Epoch 121/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2192e-04\n",
            "Epoch 122/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2375e-04\n",
            "Epoch 123/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 2.2510e-04\n",
            "Epoch 124/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.1224e-04\n",
            "Epoch 125/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.7909e-04\n",
            "Epoch 126/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.2050e-04\n",
            "Epoch 127/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.7768e-04\n",
            "Epoch 128/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.7083e-04\n",
            "Epoch 129/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.8255e-04\n",
            "Epoch 130/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.5734e-04\n",
            "Epoch 131/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.4929e-04\n",
            "Epoch 132/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.6081e-04\n",
            "Epoch 133/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.4143e-04\n",
            "Epoch 134/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.6069e-04\n",
            "Epoch 135/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.4162e-04\n",
            "Epoch 136/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.4094e-04\n",
            "Epoch 137/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.3942e-04\n",
            "Epoch 138/150\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1811e-04\n",
            "Epoch 139/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.2395e-04\n",
            "Epoch 140/150\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 1.1586e-04\n",
            "Epoch 141/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.3415e-04\n",
            "Epoch 142/150\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1326e-04\n",
            "Epoch 143/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0614e-04\n",
            "Epoch 144/150\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.2039e-04\n",
            "Epoch 145/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.0219e-04\n",
            "Epoch 146/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.1029e-05\n",
            "Epoch 147/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.8346e-05\n",
            "Epoch 148/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 8.7186e-05\n",
            "Epoch 149/150\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 8.4528e-05\n",
            "Epoch 150/150\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 8.9644e-05\n",
            "7/7 [==============================] - 0s 7ms/step - loss: 0.5988\n",
            "Accuracy: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDNcaHXzIOxc"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQC0ahgwIOxd",
        "outputId": "aa020ee8-fe24-42f2-e946-42ebeb2e8b88"
      },
      "source": [
        "#model set up\n",
        "perf=[]\n",
        "learning_rates=[0.01,0.02,0.03,0.04]\n",
        "for lr in learning_rates:\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=adamax,metrics=['accuracy'])\n",
        "    history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "    perf.append(history.history['val_accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 40ms/step - loss: 8.6279e-05 - accuracy: 1.0000 - val_loss: 0.5975 - val_accuracy: 0.9400\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.2097e-05 - accuracy: 1.0000 - val_loss: 0.6053 - val_accuracy: 0.9400\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.0579e-05 - accuracy: 1.0000 - val_loss: 0.6018 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.5237e-05 - accuracy: 1.0000 - val_loss: 0.6081 - val_accuracy: 0.9400\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.3374e-05 - accuracy: 1.0000 - val_loss: 0.6069 - val_accuracy: 0.9400\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.7769e-05 - accuracy: 1.0000 - val_loss: 0.6079 - val_accuracy: 0.9400\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.0149e-05 - accuracy: 1.0000 - val_loss: 0.6067 - val_accuracy: 0.9400\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.4240e-05 - accuracy: 1.0000 - val_loss: 0.6087 - val_accuracy: 0.9400\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 6.5917e-05 - accuracy: 1.0000 - val_loss: 0.6112 - val_accuracy: 0.9400\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 5.6568e-05 - accuracy: 1.0000 - val_loss: 0.6132 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 5.7337e-05 - accuracy: 1.0000 - val_loss: 0.6173 - val_accuracy: 0.9400\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.2496e-05 - accuracy: 1.0000 - val_loss: 0.6171 - val_accuracy: 0.9350\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 5.9555e-05 - accuracy: 1.0000 - val_loss: 0.6202 - val_accuracy: 0.9400\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 5.5327e-05 - accuracy: 1.0000 - val_loss: 0.6240 - val_accuracy: 0.9400\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 5.6775e-05 - accuracy: 1.0000 - val_loss: 0.6209 - val_accuracy: 0.9400\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 5.0764e-05 - accuracy: 1.0000 - val_loss: 0.6219 - val_accuracy: 0.9400\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 5.4386e-05 - accuracy: 1.0000 - val_loss: 0.6276 - val_accuracy: 0.9400\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 4.3518e-05 - accuracy: 1.0000 - val_loss: 0.6265 - val_accuracy: 0.9400\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.7913e-05 - accuracy: 1.0000 - val_loss: 0.6321 - val_accuracy: 0.9400\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.4657e-05 - accuracy: 1.0000 - val_loss: 0.6339 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 4.5982e-05 - accuracy: 1.0000 - val_loss: 0.6294 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 4.2981e-05 - accuracy: 1.0000 - val_loss: 0.6406 - val_accuracy: 0.9400\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.9016e-05 - accuracy: 1.0000 - val_loss: 0.6322 - val_accuracy: 0.9350\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 4.0300e-05 - accuracy: 1.0000 - val_loss: 0.6348 - val_accuracy: 0.9400\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.8960e-05 - accuracy: 1.0000 - val_loss: 0.6453 - val_accuracy: 0.9400\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.0743e-05 - accuracy: 1.0000 - val_loss: 0.6427 - val_accuracy: 0.9400\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.7369e-05 - accuracy: 1.0000 - val_loss: 0.6429 - val_accuracy: 0.9400\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.5329e-05 - accuracy: 1.0000 - val_loss: 0.6440 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.7259e-05 - accuracy: 1.0000 - val_loss: 0.6477 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.1781e-05 - accuracy: 1.0000 - val_loss: 0.6468 - val_accuracy: 0.9400\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.6841e-05 - accuracy: 1.0000 - val_loss: 0.6474 - val_accuracy: 0.9400\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.4352e-05 - accuracy: 1.0000 - val_loss: 0.6511 - val_accuracy: 0.9400\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.9291e-05 - accuracy: 1.0000 - val_loss: 0.6550 - val_accuracy: 0.9400\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.2040e-05 - accuracy: 1.0000 - val_loss: 0.6582 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.9037e-05 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.9350\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.7489e-05 - accuracy: 1.0000 - val_loss: 0.6568 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 2.8394e-05 - accuracy: 1.0000 - val_loss: 0.6609 - val_accuracy: 0.9400\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 2.6438e-05 - accuracy: 1.0000 - val_loss: 0.6704 - val_accuracy: 0.9400\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.8839e-05 - accuracy: 1.0000 - val_loss: 0.6663 - val_accuracy: 0.9400\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.6930e-05 - accuracy: 1.0000 - val_loss: 0.6640 - val_accuracy: 0.9350\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 2.3850e-05 - accuracy: 1.0000 - val_loss: 0.6716 - val_accuracy: 0.9400\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.3820e-05 - accuracy: 1.0000 - val_loss: 0.6657 - val_accuracy: 0.9350\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.2819e-05 - accuracy: 1.0000 - val_loss: 0.6765 - val_accuracy: 0.9400\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.9483e-05 - accuracy: 1.0000 - val_loss: 0.6709 - val_accuracy: 0.9350\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.9929e-05 - accuracy: 1.0000 - val_loss: 0.6779 - val_accuracy: 0.9400\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.2732e-05 - accuracy: 1.0000 - val_loss: 0.6720 - val_accuracy: 0.9350\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.0568e-05 - accuracy: 1.0000 - val_loss: 0.6822 - val_accuracy: 0.9400\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.5889e-05 - accuracy: 1.0000 - val_loss: 0.6766 - val_accuracy: 0.9350\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.0981e-05 - accuracy: 1.0000 - val_loss: 0.6797 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.8298e-05 - accuracy: 1.0000 - val_loss: 0.6833 - val_accuracy: 0.9400\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 36ms/step - loss: 1.7821e-05 - accuracy: 1.0000 - val_loss: 0.6840 - val_accuracy: 0.9400\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.7021e-05 - accuracy: 1.0000 - val_loss: 0.6910 - val_accuracy: 0.9400\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.4557e-05 - accuracy: 1.0000 - val_loss: 0.6887 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.5621e-05 - accuracy: 1.0000 - val_loss: 0.6947 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.5094e-05 - accuracy: 1.0000 - val_loss: 0.6946 - val_accuracy: 0.9400\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.3868e-05 - accuracy: 1.0000 - val_loss: 0.6941 - val_accuracy: 0.9400\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.4357e-05 - accuracy: 1.0000 - val_loss: 0.6948 - val_accuracy: 0.9400\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.5574e-05 - accuracy: 1.0000 - val_loss: 0.6950 - val_accuracy: 0.9400\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.3574e-05 - accuracy: 1.0000 - val_loss: 0.6970 - val_accuracy: 0.9400\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 33ms/step - loss: 1.1669e-05 - accuracy: 1.0000 - val_loss: 0.6993 - val_accuracy: 0.9400\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.2016e-05 - accuracy: 1.0000 - val_loss: 0.7028 - val_accuracy: 0.9400\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.3070e-05 - accuracy: 1.0000 - val_loss: 0.7030 - val_accuracy: 0.9400\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.2294e-05 - accuracy: 1.0000 - val_loss: 0.7054 - val_accuracy: 0.9400\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1417e-05 - accuracy: 1.0000 - val_loss: 0.7072 - val_accuracy: 0.9400\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.1883e-05 - accuracy: 1.0000 - val_loss: 0.7074 - val_accuracy: 0.9400\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0559e-05 - accuracy: 1.0000 - val_loss: 0.7066 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.1464e-05 - accuracy: 1.0000 - val_loss: 0.7121 - val_accuracy: 0.9400\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.0856e-06 - accuracy: 1.0000 - val_loss: 0.7112 - val_accuracy: 0.9400\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0001e-05 - accuracy: 1.0000 - val_loss: 0.7159 - val_accuracy: 0.9400\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.3322e-06 - accuracy: 1.0000 - val_loss: 0.7168 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 9.7442e-06 - accuracy: 1.0000 - val_loss: 0.7122 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.1210e-06 - accuracy: 1.0000 - val_loss: 0.7235 - val_accuracy: 0.9400\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0263e-05 - accuracy: 1.0000 - val_loss: 0.7158 - val_accuracy: 0.9350\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 8.3763e-06 - accuracy: 1.0000 - val_loss: 0.7177 - val_accuracy: 0.9350\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.1942e-06 - accuracy: 1.0000 - val_loss: 0.7280 - val_accuracy: 0.9400\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 8.5519e-06 - accuracy: 1.0000 - val_loss: 0.7267 - val_accuracy: 0.9400\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.7955e-06 - accuracy: 1.0000 - val_loss: 0.7225 - val_accuracy: 0.9350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 7.3728e-06 - accuracy: 1.0000 - val_loss: 0.7276 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 7.8026e-06 - accuracy: 1.0000 - val_loss: 0.7298 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.6353e-06 - accuracy: 1.0000 - val_loss: 0.7297 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.8944e-06 - accuracy: 1.0000 - val_loss: 0.7269 - val_accuracy: 0.9400\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 7.0900e-06 - accuracy: 1.0000 - val_loss: 0.7326 - val_accuracy: 0.9350\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 6.2178e-06 - accuracy: 1.0000 - val_loss: 0.7364 - val_accuracy: 0.9350\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 6.7975e-06 - accuracy: 1.0000 - val_loss: 0.7395 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 6.1975e-06 - accuracy: 1.0000 - val_loss: 0.7376 - val_accuracy: 0.9350\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.8779e-06 - accuracy: 1.0000 - val_loss: 0.7377 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.9468e-06 - accuracy: 1.0000 - val_loss: 0.7396 - val_accuracy: 0.9350\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.6996e-06 - accuracy: 1.0000 - val_loss: 0.7493 - val_accuracy: 0.9400\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.1386e-06 - accuracy: 1.0000 - val_loss: 0.7459 - val_accuracy: 0.9350\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.8154e-06 - accuracy: 1.0000 - val_loss: 0.7443 - val_accuracy: 0.9350\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5.1477e-06 - accuracy: 1.0000 - val_loss: 0.7530 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.1235e-06 - accuracy: 1.0000 - val_loss: 0.7445 - val_accuracy: 0.9350\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 4.8768e-06 - accuracy: 1.0000 - val_loss: 0.7562 - val_accuracy: 0.9350\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 4.1979e-06 - accuracy: 1.0000 - val_loss: 0.7501 - val_accuracy: 0.9300\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.3242e-06 - accuracy: 1.0000 - val_loss: 0.7574 - val_accuracy: 0.9350\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 4.7979e-06 - accuracy: 1.0000 - val_loss: 0.7495 - val_accuracy: 0.9300\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 4.4326e-06 - accuracy: 1.0000 - val_loss: 0.7608 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.4944e-06 - accuracy: 1.0000 - val_loss: 0.7553 - val_accuracy: 0.9300\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 4.5362e-06 - accuracy: 1.0000 - val_loss: 0.7564 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.9888e-06 - accuracy: 1.0000 - val_loss: 0.7618 - val_accuracy: 0.9350\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 37ms/step - loss: 3.8786e-06 - accuracy: 1.0000 - val_loss: 0.7615 - val_accuracy: 0.9350\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.7177e-06 - accuracy: 1.0000 - val_loss: 0.7693 - val_accuracy: 0.9350\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 3.1181e-06 - accuracy: 1.0000 - val_loss: 0.7655 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 3.3989e-06 - accuracy: 1.0000 - val_loss: 0.7717 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 3.3258e-06 - accuracy: 1.0000 - val_loss: 0.7724 - val_accuracy: 0.9350\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.9822e-06 - accuracy: 1.0000 - val_loss: 0.7723 - val_accuracy: 0.9350\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 3.1086e-06 - accuracy: 1.0000 - val_loss: 0.7761 - val_accuracy: 0.9350\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.4169e-06 - accuracy: 1.0000 - val_loss: 0.7720 - val_accuracy: 0.9350\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 2.9473e-06 - accuracy: 1.0000 - val_loss: 0.7754 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.5652e-06 - accuracy: 1.0000 - val_loss: 0.7778 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.6280e-06 - accuracy: 1.0000 - val_loss: 0.7793 - val_accuracy: 0.9350\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.9191e-06 - accuracy: 1.0000 - val_loss: 0.7815 - val_accuracy: 0.9350\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 2.6872e-06 - accuracy: 1.0000 - val_loss: 0.7832 - val_accuracy: 0.9350\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.4978e-06 - accuracy: 1.0000 - val_loss: 0.7835 - val_accuracy: 0.9350\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.5965e-06 - accuracy: 1.0000 - val_loss: 0.7868 - val_accuracy: 0.9350\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.3323e-06 - accuracy: 1.0000 - val_loss: 0.7839 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.5423e-06 - accuracy: 1.0000 - val_loss: 0.7890 - val_accuracy: 0.9350\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.9937e-06 - accuracy: 1.0000 - val_loss: 0.7882 - val_accuracy: 0.9350\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.1954e-06 - accuracy: 1.0000 - val_loss: 0.7933 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.0755e-06 - accuracy: 1.0000 - val_loss: 0.7924 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 2.1830e-06 - accuracy: 1.0000 - val_loss: 0.7899 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.0381e-06 - accuracy: 1.0000 - val_loss: 0.7995 - val_accuracy: 0.9350\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.2995e-06 - accuracy: 1.0000 - val_loss: 0.7929 - val_accuracy: 0.9300\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.8635e-06 - accuracy: 1.0000 - val_loss: 0.7938 - val_accuracy: 0.9350\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.8146e-06 - accuracy: 1.0000 - val_loss: 0.8045 - val_accuracy: 0.9350\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 1.8879e-06 - accuracy: 1.0000 - val_loss: 0.8029 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.7354e-06 - accuracy: 1.0000 - val_loss: 0.8002 - val_accuracy: 0.9350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 1.6372e-06 - accuracy: 1.0000 - val_loss: 0.8025 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 1.7353e-06 - accuracy: 1.0000 - val_loss: 0.8056 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.4851e-06 - accuracy: 1.0000 - val_loss: 0.8062 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.7911e-06 - accuracy: 1.0000 - val_loss: 0.8052 - val_accuracy: 0.9350\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.5627e-06 - accuracy: 1.0000 - val_loss: 0.8075 - val_accuracy: 0.9350\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.4122e-06 - accuracy: 1.0000 - val_loss: 0.8136 - val_accuracy: 0.9350\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.5361e-06 - accuracy: 1.0000 - val_loss: 0.8154 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.4128e-06 - accuracy: 1.0000 - val_loss: 0.8115 - val_accuracy: 0.9300\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.3612e-06 - accuracy: 1.0000 - val_loss: 0.8128 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.3447e-06 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.9350\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.3027e-06 - accuracy: 1.0000 - val_loss: 0.8248 - val_accuracy: 0.9350\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.3849e-06 - accuracy: 1.0000 - val_loss: 0.8227 - val_accuracy: 0.9350\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.3259e-06 - accuracy: 1.0000 - val_loss: 0.8205 - val_accuracy: 0.9350\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.1763e-06 - accuracy: 1.0000 - val_loss: 0.8273 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.1609e-06 - accuracy: 1.0000 - val_loss: 0.8212 - val_accuracy: 0.9350\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1129e-06 - accuracy: 1.0000 - val_loss: 0.8324 - val_accuracy: 0.9350\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 9.6154e-07 - accuracy: 1.0000 - val_loss: 0.8242 - val_accuracy: 0.9300\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 9.9343e-07 - accuracy: 1.0000 - val_loss: 0.8321 - val_accuracy: 0.9350\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 1.0840e-06 - accuracy: 1.0000 - val_loss: 0.8247 - val_accuracy: 0.9300\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.0065e-06 - accuracy: 1.0000 - val_loss: 0.8357 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 8.0815e-07 - accuracy: 1.0000 - val_loss: 0.8312 - val_accuracy: 0.9300\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 1.0367e-06 - accuracy: 1.0000 - val_loss: 0.8318 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 9.1620e-07 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.9350\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 38ms/step - loss: 8.9023e-07 - accuracy: 1.0000 - val_loss: 0.8366 - val_accuracy: 0.9350\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 8.5069e-07 - accuracy: 1.0000 - val_loss: 0.8447 - val_accuracy: 0.9350\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.0796e-07 - accuracy: 1.0000 - val_loss: 0.8415 - val_accuracy: 0.9350\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 7.7531e-07 - accuracy: 1.0000 - val_loss: 0.8461 - val_accuracy: 0.9350\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 7.6739e-07 - accuracy: 1.0000 - val_loss: 0.8477 - val_accuracy: 0.9350\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.8238e-07 - accuracy: 1.0000 - val_loss: 0.8469 - val_accuracy: 0.9350\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 7.1182e-07 - accuracy: 1.0000 - val_loss: 0.8508 - val_accuracy: 0.9350\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 7.8703e-07 - accuracy: 1.0000 - val_loss: 0.8480 - val_accuracy: 0.9350\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 6.7383e-07 - accuracy: 1.0000 - val_loss: 0.8481 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.9523e-07 - accuracy: 1.0000 - val_loss: 0.8530 - val_accuracy: 0.9350\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.1188e-07 - accuracy: 1.0000 - val_loss: 0.8546 - val_accuracy: 0.9350\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.7618e-07 - accuracy: 1.0000 - val_loss: 0.8556 - val_accuracy: 0.9350\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 6.2059e-07 - accuracy: 1.0000 - val_loss: 0.8579 - val_accuracy: 0.9350\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5.7430e-07 - accuracy: 1.0000 - val_loss: 0.8575 - val_accuracy: 0.9350\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 6.0254e-07 - accuracy: 1.0000 - val_loss: 0.8623 - val_accuracy: 0.9350\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.4576e-07 - accuracy: 1.0000 - val_loss: 0.8595 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 5.9258e-07 - accuracy: 1.0000 - val_loss: 0.8616 - val_accuracy: 0.9350\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 4.5766e-07 - accuracy: 1.0000 - val_loss: 0.8637 - val_accuracy: 0.9350\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 5.0587e-07 - accuracy: 1.0000 - val_loss: 0.8665 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 4.8223e-07 - accuracy: 1.0000 - val_loss: 0.8664 - val_accuracy: 0.9350\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 5.1375e-07 - accuracy: 1.0000 - val_loss: 0.8644 - val_accuracy: 0.9350\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 4.7784e-07 - accuracy: 1.0000 - val_loss: 0.8743 - val_accuracy: 0.9350\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 5.3110e-07 - accuracy: 1.0000 - val_loss: 0.8641 - val_accuracy: 0.9300\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.3685e-07 - accuracy: 1.0000 - val_loss: 0.8681 - val_accuracy: 0.9350\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 4.2019e-07 - accuracy: 1.0000 - val_loss: 0.8783 - val_accuracy: 0.9350\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.3893e-07 - accuracy: 1.0000 - val_loss: 0.8769 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.1022e-07 - accuracy: 1.0000 - val_loss: 0.8737 - val_accuracy: 0.9350\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.7995e-07 - accuracy: 1.0000 - val_loss: 0.8779 - val_accuracy: 0.9350\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.0620e-07 - accuracy: 1.0000 - val_loss: 0.8793 - val_accuracy: 0.9350\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.4547e-07 - accuracy: 1.0000 - val_loss: 0.8804 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 4.2283e-07 - accuracy: 1.0000 - val_loss: 0.8788 - val_accuracy: 0.9350\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.6155e-07 - accuracy: 1.0000 - val_loss: 0.8812 - val_accuracy: 0.9350\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.3292e-07 - accuracy: 1.0000 - val_loss: 0.8868 - val_accuracy: 0.9350\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.5964e-07 - accuracy: 1.0000 - val_loss: 0.8895 - val_accuracy: 0.9350\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.3106e-07 - accuracy: 1.0000 - val_loss: 0.8844 - val_accuracy: 0.9300\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.2114e-07 - accuracy: 1.0000 - val_loss: 0.8866 - val_accuracy: 0.9350\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 3.1807e-07 - accuracy: 1.0000 - val_loss: 0.8885 - val_accuracy: 0.9350\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 3.0793e-07 - accuracy: 1.0000 - val_loss: 0.8986 - val_accuracy: 0.9350\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 3.2573e-07 - accuracy: 1.0000 - val_loss: 0.8958 - val_accuracy: 0.9350\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 3.1565e-07 - accuracy: 1.0000 - val_loss: 0.8927 - val_accuracy: 0.9300\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 39ms/step - loss: 2.7952e-07 - accuracy: 1.0000 - val_loss: 0.9000 - val_accuracy: 0.9350\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 2.7412e-07 - accuracy: 1.0000 - val_loss: 0.8956 - val_accuracy: 0.9300\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 2.6504e-07 - accuracy: 1.0000 - val_loss: 0.9054 - val_accuracy: 0.9350\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 2.3024e-07 - accuracy: 1.0000 - val_loss: 0.8970 - val_accuracy: 0.9300\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - ETA: 0s - loss: 2.3656e-07 - accuracy: 1.00 - 1s 30ms/step - loss: 2.3774e-07 - accuracy: 1.0000 - val_loss: 0.9044 - val_accuracy: 0.9350\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 2.5475e-07 - accuracy: 1.0000 - val_loss: 0.8974 - val_accuracy: 0.9300\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.3549e-07 - accuracy: 1.0000 - val_loss: 0.9075 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.9333e-07 - accuracy: 1.0000 - val_loss: 0.9029 - val_accuracy: 0.9300\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 2.4631e-07 - accuracy: 1.0000 - val_loss: 0.9030 - val_accuracy: 0.9350\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.1953e-07 - accuracy: 1.0000 - val_loss: 0.9108 - val_accuracy: 0.9350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBeLTUmIIOxe"
      },
      "source": [
        "#accuracy is different for each learning rate, its 94% with a learning rate of 0.01 which is the best one"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_vlzIknIOxf",
        "outputId": "3fcf8ebf-a10a-43fc-e227-99ba8111c0a6"
      },
      "source": [
        "history.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9300000071525574,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9300000071525574,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858,\n",
              " 0.9300000071525574,\n",
              " 0.9350000023841858,\n",
              " 0.9300000071525574,\n",
              " 0.9350000023841858,\n",
              " 0.9300000071525574,\n",
              " 0.9350000023841858,\n",
              " 0.9300000071525574,\n",
              " 0.9350000023841858,\n",
              " 0.9300000071525574,\n",
              " 0.9350000023841858,\n",
              " 0.9350000023841858]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keYfnTYaIOxg",
        "outputId": "3746d911-276f-4f81-942b-2c61355d565c"
      },
      "source": [
        "tf.keras.losses"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'tensorflow.keras.losses' from 'C:\\\\Users\\\\awmna\\\\anaconda3\\\\envs\\\\myenv\\\\lib\\\\site-packages\\\\tensorflow\\\\keras\\\\losses\\\\__init__.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KQF9BomIOxi"
      },
      "source": [
        "#Adamax is the best optimizer for accuracy pf 94% and has a learning rate of 0.01 so I will use that for the next questions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwXGgKN2IOxj"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K-3waECIOxk",
        "outputId": "cd60b0ef-bba2-47d9-8006-023a4a11a6ab"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adamax=Adamax(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\")\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adamax,metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "perf.append(history.history['val_accuracy'])\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 35ms/step - loss: 2.2409 - accuracy: 0.2171 - val_loss: 1.2458 - val_accuracy: 0.7550\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.0447 - accuracy: 0.6633 - val_loss: 0.6750 - val_accuracy: 0.8500\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.7120 - accuracy: 0.7859 - val_loss: 0.4123 - val_accuracy: 0.9050\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.5692 - accuracy: 0.8454 - val_loss: 0.3335 - val_accuracy: 0.9300\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.3469 - accuracy: 0.8838 - val_loss: 0.2661 - val_accuracy: 0.9400\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.3230 - accuracy: 0.8893 - val_loss: 0.2364 - val_accuracy: 0.9300\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.3138 - accuracy: 0.9077 - val_loss: 0.2184 - val_accuracy: 0.9450\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.2501 - accuracy: 0.9379 - val_loss: 0.2160 - val_accuracy: 0.9350\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.2209 - accuracy: 0.9405 - val_loss: 0.2054 - val_accuracy: 0.9450\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1899 - accuracy: 0.9504 - val_loss: 0.2055 - val_accuracy: 0.9400\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1935 - accuracy: 0.9266 - val_loss: 0.1945 - val_accuracy: 0.9500\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1820 - accuracy: 0.9516 - val_loss: 0.2196 - val_accuracy: 0.9400\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1738 - accuracy: 0.9501 - val_loss: 0.2047 - val_accuracy: 0.9500\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1603 - accuracy: 0.9507 - val_loss: 0.2153 - val_accuracy: 0.9450\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.1608 - accuracy: 0.9433 - val_loss: 0.2214 - val_accuracy: 0.9400\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1502 - accuracy: 0.9488 - val_loss: 0.2122 - val_accuracy: 0.9400\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0978 - accuracy: 0.9700 - val_loss: 0.1915 - val_accuracy: 0.9550\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1173 - accuracy: 0.9637 - val_loss: 0.2001 - val_accuracy: 0.9400\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1381 - accuracy: 0.9524 - val_loss: 0.2224 - val_accuracy: 0.9400\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1258 - accuracy: 0.9547 - val_loss: 0.1956 - val_accuracy: 0.9550\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1134 - accuracy: 0.9692 - val_loss: 0.2298 - val_accuracy: 0.9550\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0886 - accuracy: 0.9710 - val_loss: 0.2105 - val_accuracy: 0.9550\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.1152 - accuracy: 0.9626 - val_loss: 0.1674 - val_accuracy: 0.9550\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1173 - accuracy: 0.9584 - val_loss: 0.1807 - val_accuracy: 0.9600\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0999 - accuracy: 0.9672 - val_loss: 0.1846 - val_accuracy: 0.9600\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1028 - accuracy: 0.9782 - val_loss: 0.1895 - val_accuracy: 0.9550\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0610 - accuracy: 0.9794 - val_loss: 0.1872 - val_accuracy: 0.9650\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1202 - accuracy: 0.9677 - val_loss: 0.1996 - val_accuracy: 0.9500\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0962 - accuracy: 0.9519 - val_loss: 0.2145 - val_accuracy: 0.9500\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0559 - accuracy: 0.9912 - val_loss: 0.2284 - val_accuracy: 0.9500\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0691 - accuracy: 0.9706 - val_loss: 0.1936 - val_accuracy: 0.9550\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0777 - accuracy: 0.9669 - val_loss: 0.2088 - val_accuracy: 0.9600\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0622 - accuracy: 0.9793 - val_loss: 0.2046 - val_accuracy: 0.9600\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0445 - accuracy: 0.9838 - val_loss: 0.2384 - val_accuracy: 0.9500\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0920 - accuracy: 0.9757 - val_loss: 0.2312 - val_accuracy: 0.9500\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0455 - accuracy: 0.9916 - val_loss: 0.2064 - val_accuracy: 0.9550\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0611 - accuracy: 0.9829 - val_loss: 0.2223 - val_accuracy: 0.9600\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0580 - accuracy: 0.9788 - val_loss: 0.2191 - val_accuracy: 0.9600\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0268 - accuracy: 0.9957 - val_loss: 0.2245 - val_accuracy: 0.9550\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0410 - accuracy: 0.9878 - val_loss: 0.2649 - val_accuracy: 0.9500\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0452 - accuracy: 0.9845 - val_loss: 0.2485 - val_accuracy: 0.9550\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0563 - accuracy: 0.9736 - val_loss: 0.2295 - val_accuracy: 0.9600\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0423 - accuracy: 0.9865 - val_loss: 0.2156 - val_accuracy: 0.9550\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.0506 - accuracy: 0.9845 - val_loss: 0.2286 - val_accuracy: 0.9550\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0285 - accuracy: 0.9906 - val_loss: 0.2550 - val_accuracy: 0.9550\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.0603 - accuracy: 0.9760 - val_loss: 0.2201 - val_accuracy: 0.9650\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0403 - accuracy: 0.9846 - val_loss: 0.2139 - val_accuracy: 0.9650\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.0331 - accuracy: 0.9918 - val_loss: 0.2426 - val_accuracy: 0.9650\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.0459 - accuracy: 0.9819 - val_loss: 0.2303 - val_accuracy: 0.9650\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.2278 - val_accuracy: 0.9650\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.2278 - accuracy: 0.9650\n",
            "Accuracy: 0.965\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOSsqeLsIOxl"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZegCcJRIOxm",
        "outputId": "f9083d09-14c1-49d4-f3e1-38e3cc14b3c5"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.6))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adamax=Adamax(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\")\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adamax,metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "perf.append(history.history['val_accuracy'])\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 2.3833 - accuracy: 0.1326 - val_loss: 2.0654 - val_accuracy: 0.4550\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.7308 - accuracy: 0.4128 - val_loss: 1.1116 - val_accuracy: 0.7450\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 1.1415 - accuracy: 0.6047 - val_loss: 0.6986 - val_accuracy: 0.8450\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.7926 - accuracy: 0.7312 - val_loss: 0.5131 - val_accuracy: 0.8700\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.6164 - accuracy: 0.8229 - val_loss: 0.4152 - val_accuracy: 0.8900\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5483 - accuracy: 0.8137 - val_loss: 0.3412 - val_accuracy: 0.9050\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5228 - accuracy: 0.8297 - val_loss: 0.3440 - val_accuracy: 0.8850\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5235 - accuracy: 0.8343 - val_loss: 0.2964 - val_accuracy: 0.9150\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4348 - accuracy: 0.8609 - val_loss: 0.2618 - val_accuracy: 0.9100\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.3288 - accuracy: 0.9022 - val_loss: 0.2411 - val_accuracy: 0.9300\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2902 - accuracy: 0.8933 - val_loss: 0.2393 - val_accuracy: 0.9250\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.3248 - accuracy: 0.8890 - val_loss: 0.2375 - val_accuracy: 0.9300\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2827 - accuracy: 0.9084 - val_loss: 0.2133 - val_accuracy: 0.9400\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.2938 - accuracy: 0.9117 - val_loss: 0.2349 - val_accuracy: 0.9200\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2603 - accuracy: 0.9060 - val_loss: 0.2158 - val_accuracy: 0.9250\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2505 - accuracy: 0.9136 - val_loss: 0.1825 - val_accuracy: 0.9350\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.2669 - accuracy: 0.9105 - val_loss: 0.1961 - val_accuracy: 0.9400\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2363 - accuracy: 0.9202 - val_loss: 0.2137 - val_accuracy: 0.9400\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.2341 - accuracy: 0.9040 - val_loss: 0.1907 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2796 - accuracy: 0.9262 - val_loss: 0.1952 - val_accuracy: 0.9400\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.2439 - accuracy: 0.9080 - val_loss: 0.1918 - val_accuracy: 0.9400\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1779 - accuracy: 0.9302 - val_loss: 0.1956 - val_accuracy: 0.9400\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.2058 - accuracy: 0.9366 - val_loss: 0.1906 - val_accuracy: 0.9400\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.1592 - accuracy: 0.9466 - val_loss: 0.1913 - val_accuracy: 0.9500\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1600 - accuracy: 0.9419 - val_loss: 0.1806 - val_accuracy: 0.9450\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1929 - accuracy: 0.9460 - val_loss: 0.1778 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1631 - accuracy: 0.9397 - val_loss: 0.1871 - val_accuracy: 0.9500\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.2087 - accuracy: 0.9299 - val_loss: 0.1984 - val_accuracy: 0.9500\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1863 - accuracy: 0.9418 - val_loss: 0.1965 - val_accuracy: 0.9450\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1935 - accuracy: 0.9397 - val_loss: 0.1961 - val_accuracy: 0.9450\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1560 - accuracy: 0.9545 - val_loss: 0.1898 - val_accuracy: 0.9500\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1370 - accuracy: 0.9534 - val_loss: 0.1964 - val_accuracy: 0.9450\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1313 - accuracy: 0.9537 - val_loss: 0.1853 - val_accuracy: 0.9450\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.1615 - accuracy: 0.9560 - val_loss: 0.1942 - val_accuracy: 0.9450\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.1563 - accuracy: 0.9397 - val_loss: 0.1865 - val_accuracy: 0.9400\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1523 - accuracy: 0.9493 - val_loss: 0.1767 - val_accuracy: 0.9450\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1276 - accuracy: 0.9398 - val_loss: 0.1985 - val_accuracy: 0.9450\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1364 - accuracy: 0.9593 - val_loss: 0.1951 - val_accuracy: 0.9450\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1055 - accuracy: 0.9668 - val_loss: 0.2078 - val_accuracy: 0.9450\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1492 - accuracy: 0.9552 - val_loss: 0.1974 - val_accuracy: 0.9450\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1390 - accuracy: 0.9406 - val_loss: 0.2008 - val_accuracy: 0.9450\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.1112 - accuracy: 0.9642 - val_loss: 0.1841 - val_accuracy: 0.9450\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1230 - accuracy: 0.9502 - val_loss: 0.1864 - val_accuracy: 0.9450\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.1115 - accuracy: 0.9649 - val_loss: 0.2003 - val_accuracy: 0.9450\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.1133 - accuracy: 0.9615 - val_loss: 0.1757 - val_accuracy: 0.9450\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1070 - accuracy: 0.9686 - val_loss: 0.2058 - val_accuracy: 0.9500\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.1599 - accuracy: 0.9418 - val_loss: 0.2243 - val_accuracy: 0.9350\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.1144 - accuracy: 0.9656 - val_loss: 0.1942 - val_accuracy: 0.9400\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.1174 - accuracy: 0.9592 - val_loss: 0.2106 - val_accuracy: 0.9400\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.0793 - accuracy: 0.9709 - val_loss: 0.1881 - val_accuracy: 0.9450\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1881 - accuracy: 0.9450\n",
            "Accuracy: 0.945\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycq_KEEUIOxn"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBYEeBcxIOxo",
        "outputId": "12822bdc-7d9b-4265-a05c-65bd531d8975"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adamax=Adamax(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\")\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adamax,metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "perf.append(history.history['val_accuracy'])\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 35ms/step - loss: 2.3637 - accuracy: 0.1473 - val_loss: 2.1741 - val_accuracy: 0.3750\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.9067 - accuracy: 0.3191 - val_loss: 1.6688 - val_accuracy: 0.6650\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.4666 - accuracy: 0.5034 - val_loss: 1.0708 - val_accuracy: 0.7650\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.2652 - accuracy: 0.5880 - val_loss: 0.8474 - val_accuracy: 0.8300\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.0511 - accuracy: 0.6755 - val_loss: 0.7606 - val_accuracy: 0.8800\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.9603 - accuracy: 0.6426 - val_loss: 0.6819 - val_accuracy: 0.8900\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.9809 - accuracy: 0.6660 - val_loss: 0.5476 - val_accuracy: 0.8950\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.8278 - accuracy: 0.7142 - val_loss: 0.4821 - val_accuracy: 0.8950\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.7812 - accuracy: 0.7463 - val_loss: 0.4809 - val_accuracy: 0.9100\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.7296 - accuracy: 0.7574 - val_loss: 0.4156 - val_accuracy: 0.8850\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.6516 - accuracy: 0.7744 - val_loss: 0.3469 - val_accuracy: 0.9050\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.7471 - accuracy: 0.7744 - val_loss: 0.3448 - val_accuracy: 0.9300\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.6619 - accuracy: 0.7762 - val_loss: 0.3089 - val_accuracy: 0.9200\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.6189 - accuracy: 0.8056 - val_loss: 0.3141 - val_accuracy: 0.9100\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.6343 - accuracy: 0.7773 - val_loss: 0.2978 - val_accuracy: 0.9300\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.5323 - accuracy: 0.8289 - val_loss: 0.3011 - val_accuracy: 0.9100\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5651 - accuracy: 0.8137 - val_loss: 0.2876 - val_accuracy: 0.9400\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.4976 - accuracy: 0.8420 - val_loss: 0.2838 - val_accuracy: 0.9300\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.5242 - accuracy: 0.8005 - val_loss: 0.2551 - val_accuracy: 0.9350\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.6434 - accuracy: 0.8169 - val_loss: 0.2484 - val_accuracy: 0.9500\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.5078 - accuracy: 0.8384 - val_loss: 0.2225 - val_accuracy: 0.9450\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5699 - accuracy: 0.8164 - val_loss: 0.2399 - val_accuracy: 0.9250\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.5299 - accuracy: 0.8184 - val_loss: 0.2276 - val_accuracy: 0.9350\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4856 - accuracy: 0.8261 - val_loss: 0.2572 - val_accuracy: 0.9200\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4647 - accuracy: 0.8481 - val_loss: 0.2351 - val_accuracy: 0.9400\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.4811 - accuracy: 0.8344 - val_loss: 0.2298 - val_accuracy: 0.9350\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.3946 - accuracy: 0.8833 - val_loss: 0.2279 - val_accuracy: 0.9400\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.4846 - accuracy: 0.8380 - val_loss: 0.2182 - val_accuracy: 0.9450\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.4405 - accuracy: 0.8450 - val_loss: 0.2109 - val_accuracy: 0.9400\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 38ms/step - loss: 0.3946 - accuracy: 0.8597 - val_loss: 0.2093 - val_accuracy: 0.9350\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.4141 - accuracy: 0.8709 - val_loss: 0.2004 - val_accuracy: 0.9400\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.4087 - accuracy: 0.8468 - val_loss: 0.1991 - val_accuracy: 0.9450\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.4320 - accuracy: 0.8327 - val_loss: 0.1882 - val_accuracy: 0.9450\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.4154 - accuracy: 0.8366 - val_loss: 0.1829 - val_accuracy: 0.9500\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4163 - accuracy: 0.8793 - val_loss: 0.1920 - val_accuracy: 0.9450\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.3705 - accuracy: 0.8559 - val_loss: 0.1908 - val_accuracy: 0.9450\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.3924 - accuracy: 0.8604 - val_loss: 0.1873 - val_accuracy: 0.9600\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.3970 - accuracy: 0.8556 - val_loss: 0.1891 - val_accuracy: 0.9400\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.4062 - accuracy: 0.8507 - val_loss: 0.1856 - val_accuracy: 0.9500\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3655 - accuracy: 0.8642 - val_loss: 0.1622 - val_accuracy: 0.9550\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3603 - accuracy: 0.8720 - val_loss: 0.1558 - val_accuracy: 0.9550\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3397 - accuracy: 0.8712 - val_loss: 0.1646 - val_accuracy: 0.9550\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.4153 - accuracy: 0.8727 - val_loss: 0.1567 - val_accuracy: 0.9550\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 0.3201 - accuracy: 0.8743 - val_loss: 0.1668 - val_accuracy: 0.9600\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3469 - accuracy: 0.8622 - val_loss: 0.1644 - val_accuracy: 0.9400\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3765 - accuracy: 0.8830 - val_loss: 0.1479 - val_accuracy: 0.9550\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.3070 - accuracy: 0.9075 - val_loss: 0.1776 - val_accuracy: 0.9500\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3419 - accuracy: 0.8669 - val_loss: 0.1669 - val_accuracy: 0.9550\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3494 - accuracy: 0.8647 - val_loss: 0.1800 - val_accuracy: 0.9400\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.3676 - accuracy: 0.8601 - val_loss: 0.1651 - val_accuracy: 0.9550\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.1651 - accuracy: 0.9550\n",
            "Accuracy: 0.955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO9V5tQ5IOxp"
      },
      "source": [
        "model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P6zwwQUIOxp",
        "outputId": "0b49c314-d817-4450-ec99-d00f1f8e8249"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adamax=Adamax(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\")\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adamax,metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "perf.append(history.history['val_accuracy'])\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 45ms/step - loss: 2.6828 - accuracy: 0.0926 - val_loss: 2.3034 - val_accuracy: 0.1000\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 2.2846 - accuracy: 0.1562 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 2.2387 - accuracy: 0.2000 - val_loss: 2.2571 - val_accuracy: 0.2950\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 2.1410 - accuracy: 0.2061 - val_loss: 2.1404 - val_accuracy: 0.4400\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.9823 - accuracy: 0.2772 - val_loss: 2.0329 - val_accuracy: 0.5650\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.9317 - accuracy: 0.3033 - val_loss: 1.9351 - val_accuracy: 0.6300\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.7887 - accuracy: 0.3384 - val_loss: 1.7893 - val_accuracy: 0.7050\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.6874 - accuracy: 0.4067 - val_loss: 1.6578 - val_accuracy: 0.7500\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.6088 - accuracy: 0.4096 - val_loss: 1.6290 - val_accuracy: 0.7600\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.4459 - accuracy: 0.5182 - val_loss: 1.4898 - val_accuracy: 0.7900\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.4031 - accuracy: 0.4958 - val_loss: 1.4741 - val_accuracy: 0.8150\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.4533 - accuracy: 0.4896 - val_loss: 1.2858 - val_accuracy: 0.7850\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3243 - accuracy: 0.5113 - val_loss: 1.2684 - val_accuracy: 0.8350\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.3629 - accuracy: 0.5194 - val_loss: 1.1019 - val_accuracy: 0.8550\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.3934 - accuracy: 0.4798 - val_loss: 1.1541 - val_accuracy: 0.8700\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.2676 - accuracy: 0.5474 - val_loss: 0.9636 - val_accuracy: 0.8750\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1974 - accuracy: 0.5698 - val_loss: 0.9211 - val_accuracy: 0.8800\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1302 - accuracy: 0.5967 - val_loss: 0.8951 - val_accuracy: 0.8500\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 1.1219 - accuracy: 0.5586 - val_loss: 0.8513 - val_accuracy: 0.8700\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.2698 - accuracy: 0.5540 - val_loss: 0.8055 - val_accuracy: 0.8600\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0878 - accuracy: 0.6091 - val_loss: 0.7529 - val_accuracy: 0.8600\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.0988 - accuracy: 0.5994 - val_loss: 0.7347 - val_accuracy: 0.8900\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 1.1314 - accuracy: 0.5980 - val_loss: 0.7227 - val_accuracy: 0.8750\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.0217 - accuracy: 0.6279 - val_loss: 0.6256 - val_accuracy: 0.8850\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.0654 - accuracy: 0.5974 - val_loss: 0.5977 - val_accuracy: 0.8900\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 1.0137 - accuracy: 0.6597 - val_loss: 0.6030 - val_accuracy: 0.8700\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 29ms/step - loss: 0.9283 - accuracy: 0.6317 - val_loss: 0.6058 - val_accuracy: 0.8900\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.0376 - accuracy: 0.6139 - val_loss: 0.6200 - val_accuracy: 0.8850\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.0150 - accuracy: 0.6296 - val_loss: 0.5869 - val_accuracy: 0.8850\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.9676 - accuracy: 0.6421 - val_loss: 0.5868 - val_accuracy: 0.9050\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.1065 - accuracy: 0.5945 - val_loss: 0.5981 - val_accuracy: 0.9050\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 1.0388 - accuracy: 0.5870 - val_loss: 0.5821 - val_accuracy: 0.9100\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0331 - accuracy: 0.6073 - val_loss: 0.5694 - val_accuracy: 0.9100\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 26ms/step - loss: 0.9914 - accuracy: 0.6554 - val_loss: 0.5618 - val_accuracy: 0.9000\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 1.0029 - accuracy: 0.6124 - val_loss: 0.5363 - val_accuracy: 0.9000\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 27ms/step - loss: 0.8932 - accuracy: 0.6735 - val_loss: 0.5464 - val_accuracy: 0.9150\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 34ms/step - loss: 0.9745 - accuracy: 0.6644 - val_loss: 0.5946 - val_accuracy: 0.9050\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.9557 - accuracy: 0.6473 - val_loss: 0.5350 - val_accuracy: 0.9000\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8422 - accuracy: 0.6699 - val_loss: 0.4953 - val_accuracy: 0.9050\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.9925 - accuracy: 0.6164 - val_loss: 0.5051 - val_accuracy: 0.9100\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8492 - accuracy: 0.6709 - val_loss: 0.4830 - val_accuracy: 0.9150\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8680 - accuracy: 0.6803 - val_loss: 0.4718 - val_accuracy: 0.9100\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8666 - accuracy: 0.6807 - val_loss: 0.4585 - val_accuracy: 0.9000\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8794 - accuracy: 0.6797 - val_loss: 0.4606 - val_accuracy: 0.8900\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 0.8352 - accuracy: 0.6962 - val_loss: 0.4974 - val_accuracy: 0.9150\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 28ms/step - loss: 0.9731 - accuracy: 0.6309 - val_loss: 0.4899 - val_accuracy: 0.9150\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 30ms/step - loss: 0.9182 - accuracy: 0.6478 - val_loss: 0.4761 - val_accuracy: 0.9150\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.8532 - accuracy: 0.6859 - val_loss: 0.4330 - val_accuracy: 0.9050\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.9327 - accuracy: 0.6689 - val_loss: 0.4716 - val_accuracy: 0.9150\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 31ms/step - loss: 0.8168 - accuracy: 0.6836 - val_loss: 0.4660 - val_accuracy: 0.9200\n",
            "7/7 [==============================] - 0s 8ms/step - loss: 0.4660 - accuracy: 0.9200\n",
            "Accuracy: 0.92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSBYgEtUIOxq"
      },
      "source": [
        "#i tested dropout rates of 0 which was given as well as 0.5 to 0.8 because i found that this was the most common dropout rates\n",
        "#dropout rate of 0.5 gives a higher accuracy than 0,0.6,0.7,and 0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77R-qAc3IOxr",
        "outputId": "b3281826-cae2-4671-d8f1-9686d71779ed"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "# Max pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "adamax=Adamax(learning_rate=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name=\"Adamax\")\n",
        "\n",
        "tf.keras.losses.CategoricalCrossentropy(\n",
        "    from_logits=False,\n",
        "    label_smoothing=0,\n",
        "    reduction=\"auto\",\n",
        "    name=\"categorical_crossentropy\",\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adamax,metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history=model.fit(X_train, y_oh_train, batch_size=32, epochs=50,validation_data=(X_test,y_oh_test))\n",
        "perf.append(history.history['val_accuracy'])\n",
        "\n",
        "# Evaluate performance\n",
        "test_loss = model.evaluate(X_test, y_oh_test, batch_size=32)\n",
        "\n",
        "predictions = model.predict(X_test, batch_size=32)\n",
        "predictions = np.argmax(predictions, axis=1) # change encoding again\n",
        "print('Accuracy:', (predictions == y_test).sum() / predictions.shape[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 2s 33ms/step - loss: 1.8089 - accuracy: 0.4306 - val_loss: 0.5593 - val_accuracy: 0.8550\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.3422 - accuracy: 0.8991 - val_loss: 0.3799 - val_accuracy: 0.8950\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1885 - accuracy: 0.9395 - val_loss: 0.3331 - val_accuracy: 0.9100\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 0.1810 - accuracy: 0.9524 - val_loss: 0.3401 - val_accuracy: 0.9200\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.1057 - accuracy: 0.9678 - val_loss: 0.2953 - val_accuracy: 0.9400\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0467 - accuracy: 0.9872 - val_loss: 0.3494 - val_accuracy: 0.9250\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0436 - accuracy: 0.9888 - val_loss: 0.3043 - val_accuracy: 0.9400\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0273 - accuracy: 0.9981 - val_loss: 0.3339 - val_accuracy: 0.9400\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0166 - accuracy: 0.9993 - val_loss: 0.3563 - val_accuracy: 0.9350\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0088 - accuracy: 0.9996 - val_loss: 0.3657 - val_accuracy: 0.9400\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9400\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9400\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9400\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9400\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9400\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9400\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9400\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 9.6291e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9400\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9400\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 9.0164e-04 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9400\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 8.2290e-04 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9400\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 8.0725e-04 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9400\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 1s 21ms/step - loss: 6.9193e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9400\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.3755e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9400\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 5.5804e-04 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9400\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 5.2067e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9400\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 4.5661e-04 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.9400\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.3811e-04 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9400\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 4.4481e-04 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.9400\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 1s 25ms/step - loss: 3.5162e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9400\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 3.5928e-04 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9400\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 3.7467e-04 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9400\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.8469e-04 - accuracy: 1.0000 - val_loss: 0.5143 - val_accuracy: 0.9400\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.9855e-04 - accuracy: 1.0000 - val_loss: 0.5195 - val_accuracy: 0.9400\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.5402e-04 - accuracy: 1.0000 - val_loss: 0.5239 - val_accuracy: 0.9400\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.3495e-04 - accuracy: 1.0000 - val_loss: 0.5275 - val_accuracy: 0.9400\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.3157e-04 - accuracy: 1.0000 - val_loss: 0.5348 - val_accuracy: 0.9400\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 2.0912e-04 - accuracy: 1.0000 - val_loss: 0.5397 - val_accuracy: 0.9400\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 1s 22ms/step - loss: 2.1457e-04 - accuracy: 1.0000 - val_loss: 0.5494 - val_accuracy: 0.9400\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.9230e-04 - accuracy: 1.0000 - val_loss: 0.5520 - val_accuracy: 0.9400\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.7561e-04 - accuracy: 1.0000 - val_loss: 0.5600 - val_accuracy: 0.9400\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.6932e-04 - accuracy: 1.0000 - val_loss: 0.5637 - val_accuracy: 0.9400\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.4994e-04 - accuracy: 1.0000 - val_loss: 0.5759 - val_accuracy: 0.9400\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.2182e-04 - accuracy: 1.0000 - val_loss: 0.5794 - val_accuracy: 0.9400\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.2448e-04 - accuracy: 1.0000 - val_loss: 0.5857 - val_accuracy: 0.9400\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.3904e-04 - accuracy: 1.0000 - val_loss: 0.5933 - val_accuracy: 0.9400\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 1.0504e-04 - accuracy: 1.0000 - val_loss: 0.5999 - val_accuracy: 0.9400\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 8.4464e-05 - accuracy: 1.0000 - val_loss: 0.6062 - val_accuracy: 0.9400\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 1s 24ms/step - loss: 1.0565e-04 - accuracy: 1.0000 - val_loss: 0.6120 - val_accuracy: 0.9400\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 1s 23ms/step - loss: 8.8725e-05 - accuracy: 1.0000 - val_loss: 0.6234 - val_accuracy: 0.9400\n",
            "7/7 [==============================] - 0s 6ms/step - loss: 0.6234 - accuracy: 0.9400\n",
            "Accuracy: 0.94\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCSerivcIOxs"
      },
      "source": [
        "#i tested the dropout rate of 0 and it gave a accuracy of 94% which is less than the accuracy with a dropout of 0.5\n",
        "#therefore the best model is adamax, learning rate of 0.01 and dropout rate of 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfN6X_oyIOxt",
        "outputId": "1a7252c1-f5d3-473d-ad01-08d5ce9a0683"
      },
      "source": [
        "history.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.10000000149011612,\n",
              " 0.10000000149011612,\n",
              " 0.29499998688697815,\n",
              " 0.4399999976158142,\n",
              " 0.5649999976158142,\n",
              " 0.6299999952316284,\n",
              " 0.7049999833106995,\n",
              " 0.75,\n",
              " 0.7599999904632568,\n",
              " 0.7900000214576721,\n",
              " 0.8149999976158142,\n",
              " 0.7850000262260437,\n",
              " 0.8349999785423279,\n",
              " 0.8550000190734863,\n",
              " 0.8700000047683716,\n",
              " 0.875,\n",
              " 0.8799999952316284,\n",
              " 0.8500000238418579,\n",
              " 0.8700000047683716,\n",
              " 0.8600000143051147,\n",
              " 0.8600000143051147,\n",
              " 0.8899999856948853,\n",
              " 0.875,\n",
              " 0.8849999904632568,\n",
              " 0.8899999856948853,\n",
              " 0.8700000047683716,\n",
              " 0.8899999856948853,\n",
              " 0.8849999904632568,\n",
              " 0.8849999904632568,\n",
              " 0.9049999713897705,\n",
              " 0.9049999713897705,\n",
              " 0.9100000262260437,\n",
              " 0.9100000262260437,\n",
              " 0.8999999761581421,\n",
              " 0.8999999761581421,\n",
              " 0.9150000214576721,\n",
              " 0.9049999713897705,\n",
              " 0.8999999761581421,\n",
              " 0.9049999713897705,\n",
              " 0.9100000262260437,\n",
              " 0.9150000214576721,\n",
              " 0.9100000262260437,\n",
              " 0.8999999761581421,\n",
              " 0.8899999856948853,\n",
              " 0.9150000214576721,\n",
              " 0.9150000214576721,\n",
              " 0.9150000214576721,\n",
              " 0.9049999713897705,\n",
              " 0.9150000214576721,\n",
              " 0.9200000166893005]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6oxgesiIOxu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}